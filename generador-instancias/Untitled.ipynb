{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (parser.py, line 22)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-4897fb770a08>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import parser\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/muro/proygrado/generador-instancias/parser.py\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    output-directory'\u001b[0m\n\u001b[0m                     \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "# coding = utf-8\n",
    "'''\n",
    "This script generates classifiers trained using data in a directory passed by parameter, and persists them\n",
    "in another one (also passed by parameter).\n",
    "'''\n",
    "# Imports.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import generar_jobs\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Runtime configuration.\n",
    "DEBUG_MODE = False\n",
    "SCALE_DATA = True\n",
    "USE_PARAMETER_SELECTION = False\n",
    "# Classifier ID information.\n",
    "CLASSIFIER_STRING_ANN = 'ann'\n",
    "CLASSIFIER_STRING_SVM = 'svm'\n",
    "classifier_types = [CLASSIFIER_STRING_ANN, CLASSIFIER_STRING_SVM]\n",
    "# Problem definition parameters (to be received as user input).\n",
    "task_amount = None\n",
    "machine_amount = None\n",
    "task_heterogeneity = None\n",
    "machine_heterogeneity = None\n",
    "consistency_type = None\n",
    "USING_ENTIRE_ETC = None\n",
    "chosen_classifier_index = None\n",
    "# Result holders.\n",
    "accuracy_scores = []\n",
    "classifiers = []\n",
    "MODEL_FILE_EXTENSION = '.pkl'\n",
    "MODEL_FILE_PREFIX = 'clf-'\n",
    "\n",
    "\n",
    "def main():\n",
    "    global task_amount, machine_amount, task_heterogeneity, machine_heterogeneity, consistency_type, USING_ENTIRE_ETC\n",
    "    global chosen_classifier_index, accuracy_scores, classifiers\n",
    "    # The problem specification is obtained from the user input.\n",
    "    try:\n",
    "        task_amount = 128\n",
    "        machine_amount = 4\n",
    "        task_heterogeneity = 0\n",
    "        machine_heterogeneity = 0\n",
    "        consistency_type = 0\n",
    "        USING_ENTIRE_ETC = sys.argv[6] == 'True'\n",
    "        chosen_classifier_index = 0\n",
    "    except Exception:\n",
    "        print('arguments were: ' + str(sys.argv))\n",
    "        print('Usage: python classifier_generator.py task_amount\\n\\\n",
    "        machine_amount task_heterogeneity machine_heterogeneity\\n\\\n",
    "        consistency_type USING_ENTIRE_ETC chosen_classifier_index')\n",
    "        print('### Types ###')\n",
    "        print('task_amount : int')\n",
    "        print('machine_amount : int')\n",
    "        print('task_heterogeneity : 0 = Low, 1 = High')\n",
    "        print('machine_heterogeneity : 0 = Low, 1 = High')\n",
    "        print('consistency_type : 0 = Consistent, 1 = Semiconsistent, 2 = Inconsistent')\n",
    "        print('USING_ENTIRE_ETC : Boolean')\n",
    "        print('chosen_classifier_index : 0 = \\'ann\\', 1 = \\'svm\\'')\n",
    "        print('Example: python classifier_generator.py 128 4 0 0 0 True 1')\n",
    "        return\n",
    "    chosen_classifier = classifier_types[chosen_classifier_index]\n",
    "    # Get path of where all of the models are.\n",
    "    model_base_path = create_or_load_classifiers(chosen_classifier)\n",
    "    # No threading version.\n",
    "    start = time.time()\n",
    "    # Each index corresponds to an instance.\n",
    "    makespan_instance_machines_heuristic = []\n",
    "    makespan_instance_machines_prediction = []\n",
    "    # Within each index, there'll be an array of machine_amount elements, in which each element\n",
    "    # is the time during which each machine is running\n",
    "    # Something along the lines of [[10,20,9,40], [99,88,22,11], ..., [10,9,21,35]]\n",
    "    for i in range(0, task_amount):  # For each task/classifier\n",
    "        if (DEBUG_MODE):\n",
    "            print(\"Training classifier \" + str(i) + \"...\")\n",
    "        # Data is loaded.\n",
    "        # Training file for current classifier\n",
    "        # TODO make data-processed dir configurable since it's configurable from job generation script.\n",
    "        baseDir = './data-processed/' + str(task_amount) + 'x' \\\n",
    "            + str(machine_amount) + '-' + str(task_heterogeneity) \\\n",
    "            + str(machine_heterogeneity) + str(consistency_type) + '/'\n",
    "        TRAINING_FILE = baseDir + 'training/' + str(i) + '.csv'\n",
    "        # Test file for current classifier\n",
    "        TEST_FILE = baseDir + 'test/' + str(i) + '.csv'\n",
    "        training_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "        test_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "\n",
    "        # Create dataframe for data and separate target.\n",
    "        df_training = pd.DataFrame(training_set)\n",
    "        # Leave rows alone, slice everything except last column.\n",
    "        df_training_input = df_training.iloc[:, :-1]\n",
    "        # If not using entire ETC,use only the column relevant to the task/classifier.\n",
    "        if not USING_ENTIRE_ETC:\n",
    "            df_training_input = df_training_input.iloc[:, i *\n",
    "                                                       machine_amount: i * machine_amount + machine_amount]\n",
    "        df_training_output = df_training.iloc[:, -1]\n",
    "\n",
    "        # Validation/testing data is loaded.\n",
    "        df_test = pd.DataFrame(test_set)\n",
    "        df_test_input = df_test.iloc[:, :-1]\n",
    "        # If not using entire ETC,use only the column relevant to the task/classifier.\n",
    "        if not USING_ENTIRE_ETC:\n",
    "            df_test_input = df_test_input.iloc[:, i *\n",
    "                                               machine_amount: i * machine_amount + machine_amount]\n",
    "        df_test_output = df_test.iloc[:, -1]\n",
    "        if SCALE_DATA:\n",
    "            # Scale data because http://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use\n",
    "            scaler = StandardScaler()\n",
    "            # Fit only on training data.\n",
    "            scaler.fit(df_training_input)\n",
    "            # Reconvert input training data to dataframe after scaling (which converts it to an array of arrays).\n",
    "            df_training_input = pd.DataFrame(\n",
    "                scaler.transform(df_training_input))\n",
    "            # Re-init scaler just in case.\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df_test_input)\n",
    "            # Scale test data.\n",
    "            df_test_input = pd.DataFrame(scaler.transform(df_test_input))\n",
    "            print (df_training_input)\n",
    "        if chosen_classifier == CLASSIFIER_STRING_SVM:\n",
    "            if USE_PARAMETER_SELECTION:\n",
    "                # Grid of parameters, including all posible parameters for each configuration of\n",
    "                # an SVM classifier.\n",
    "                param_grid = [\n",
    "                    {'C': [1, 10, 100, 1000], 'gamma': [\n",
    "                        0.001, 0.0001], 'kernel': ['rbf']}\n",
    "                ]\n",
    "                # Run grid search with all the possible classifier configurations.\n",
    "                classifiers[i] = GridSearchCV(\n",
    "                    classifiers[i], param_grid=param_grid)\n",
    "                # This generates multiple estimators.\n",
    "                # Now the prediction will use the best estimator of all.\n",
    "                # Should use grid_search as new classifier, persist it, and use it for prediction\n",
    "                # as a normal classifier (according to documentation it uses the best estimator)\n",
    "                # However, it fits every possible estimator with the data, so that's something of note.\n",
    "        # Classifier is trained using the data.\n",
    "        print(\"here\")\n",
    "\n",
    "        classifiers[i].fit(df_training_input, df_training_output)\n",
    "        # Classifier directory is generated if it doesn't exist.\n",
    "        if (not DEBUG_MODE):\n",
    "            blockPrint()\n",
    "        generar_jobs.generate_dir(model_base_path)\n",
    "        if (not DEBUG_MODE):\n",
    "            enablePrint()\n",
    "        # Classifier is persisted.\n",
    "        joblib.dump(classifiers[i], getModelPathStr(model_base_path, chosen_classifier, i))\n",
    "        # Classifier accuracy is determined using test data.\n",
    "        results = []\n",
    "        # Go through every test instance manually to calculate makespan for each\n",
    "        # problem-classifier/task pair\n",
    "        current_task_index = i * machine_amount  # Column index within etc matrix\n",
    "        if (DEBUG_MODE):\n",
    "            print(\"    Doing makespan stuff...\")\n",
    "        test_instance_amount = len(df_test)\n",
    "        for j in range(0, test_instance_amount):  # For every validation instance\n",
    "            if USING_ENTIRE_ETC:\n",
    "                # df_test.iloc[j] is an ETC matrix + the corresponding classification for one task\n",
    "                # Scaled data for classification (since classifiers were\n",
    "                etc_matrix_scaled = df_test_input.iloc[j]\n",
    "                # trained using scaled data)\n",
    "                # Non-scaled data is used to calculate real makespan, using the original units of the problem.\n",
    "                # Get j problem instance, ignoring last column (the output/classification).\n",
    "                etc_matrix = df_test.iloc[j][:-1]\n",
    "                classification_heuristic = float(df_test_output[j])\n",
    "                # Every test example is classified, and its classification is appended\n",
    "                # to a results array.\n",
    "                # Make prediction for current problem instance or etc matrix (using scaled data).\n",
    "                prediction_pandas = float(classifiers[i].predict(\n",
    "                    etc_matrix_scaled.values.reshape(1, -1)))\n",
    "                results.append(prediction_pandas)\n",
    "                prediction = float(prediction_pandas)  # To work in floats.\n",
    "\n",
    "                # Get subrow from original input data, to get the task/machine times right.\n",
    "                sub_row_for_current_task = etc_matrix[current_task_index:\n",
    "                                                      current_task_index + machine_amount]\n",
    "                # Makespan value for prediction\n",
    "                current_makespan_prediction = sub_row_for_current_task[current_task_index + prediction]\n",
    "                # Makespan value for heuristic\n",
    "                current_makespan_heuristic = sub_row_for_current_task[\n",
    "                    current_task_index + classification_heuristic]\n",
    "                # If there's no entry for this problem instance.\n",
    "                if len(makespan_instance_machines_prediction) <= j:\n",
    "                    # Init entry for problem instance, with each machine's makespan starting at 0.0.\n",
    "                    makespan_instance_machines_prediction.append(\n",
    "                        [0.0] * machine_amount)\n",
    "                    makespan_instance_machines_heuristic.append(\n",
    "                        [0.0] * machine_amount)\n",
    "                makespan_instance_machines_prediction[j][int(\n",
    "                    prediction)] += current_makespan_prediction\n",
    "                makespan_instance_machines_heuristic[j][int(\n",
    "                    classification_heuristic)] += current_makespan_heuristic\n",
    "            else:\n",
    "                # df_test.iloc[j] is an ETC matrix + the corresponding classification for one task\n",
    "                # Scaled data for classification (since classifiers were\n",
    "                sub_row_for_current_task_scaled = df_test_input.iloc[j]\n",
    "                # trained using scaled data)\n",
    "                # Non-scaled data is used to calculate real makespan, using the original units of the problem.\n",
    "                sub_row_for_current_task = df_test.iloc[:, :-1].iloc[j,\n",
    "                                                                     i * machine_amount: i * machine_amount + machine_amount]\n",
    "                classification_heuristic = float(df_test_output[j])\n",
    "                # Every test example is classified, and its classification is appended\n",
    "                # to a results array.\n",
    "                # Make prediction for current problem instance or etc matrix (using scaled data).\n",
    "                prediction_pandas = float(classifiers[i].predict(\n",
    "                    sub_row_for_current_task_scaled.values.reshape(1, -1)))\n",
    "                results.append(prediction_pandas)\n",
    "                prediction = float(prediction_pandas)  # To work in floats.\n",
    "                # Makespan value for prediction\n",
    "                current_makespan_prediction = sub_row_for_current_task[current_task_index + prediction]\n",
    "                # Makespan value for heuristic\n",
    "                current_makespan_heuristic = sub_row_for_current_task[\n",
    "                    current_task_index + classification_heuristic]\n",
    "                # If there's no entry for this problem instance.\n",
    "                if len(makespan_instance_machines_prediction) <= j:\n",
    "                    # Init entry for problem instance, with each machine's makespan starting at 0.0.\n",
    "                    makespan_instance_machines_prediction.append(\n",
    "                        [0.0] * machine_amount)\n",
    "                    makespan_instance_machines_heuristic.append(\n",
    "                        [0.0] * machine_amount)\n",
    "                makespan_instance_machines_prediction[j][int(\n",
    "                    prediction)] += current_makespan_prediction\n",
    "                makespan_instance_machines_heuristic[j][int(\n",
    "                    classification_heuristic)] += current_makespan_heuristic\n",
    "        if (DEBUG_MODE):\n",
    "            print(\"    Done with makespan stuff...\")\n",
    "        # Actual classification results are compared to expected values.\n",
    "        accuracy = accuracy_score(df_test_output, results)\n",
    "        if (DEBUG_MODE):\n",
    "            print(\"    Classifier accuracy: \" + str(accuracy))\n",
    "        # Calculated accuracy is added to accuracies list.\n",
    "        accuracy_scores.append(accuracy)\n",
    "    end = time.time()\n",
    "    if (DEBUG_MODE):\n",
    "        print('Training took ' + str(end - start) + ' seconds')\n",
    "    ################################################################################################################################################################################\n",
    "    ################################################################################################################################################################################\n",
    "    ################################################################################################################################################################################\n",
    "    ################################################################################################################################################################################\n",
    "    # Array that holds makespan values for the prediction.\n",
    "    makespan_prediction = []\n",
    "    for i in range(0, len(makespan_instance_machines_prediction)):\n",
    "        makespan_prediction.append(\n",
    "            np.max(makespan_instance_machines_prediction[i]))\n",
    "    # Array that holds makespan values for the heuristic\n",
    "    makespan_heuristic = []\n",
    "    for i in range(0, len(makespan_instance_machines_heuristic)):\n",
    "        makespan_heuristic.append(\n",
    "            np.max(makespan_instance_machines_heuristic[i]))\n",
    "    # Array that holds the difference between heuristic and prediction makespan.\n",
    "    makespan_diff = []\n",
    "    for i in range(0, len(makespan_prediction)):\n",
    "        makespan_diff.append(makespan_prediction[i] - makespan_heuristic[i])\n",
    "    # Calculate average difference between methods.\n",
    "    avg_difference_between_methods = np.mean(makespan_diff)\n",
    "    if (DEBUG_MODE):\n",
    "        print('Average difference between techniques: ' +\n",
    "              str(avg_difference_between_methods))\n",
    "        if avg_difference_between_methods > 0:\n",
    "            print('The heuristic works better on average')\n",
    "        elif avg_difference_between_methods < 0:\n",
    "            print('Savant works better on average')\n",
    "        else:\n",
    "            print('Both techniques work equivalently on average')\n",
    "    ################################################################################################################################################################################\n",
    "    ################################################################################################################################################################################\n",
    "    ################################################################################################################################################################################\n",
    "    ################################################################################################################################################################################\n",
    "    # Average accuracy (for all classifiers) is calculated (nothing to do with threading).\n",
    "    average_accuracy = 0.\n",
    "    score_amount = len(accuracy_scores)\n",
    "    for i in range(0, score_amount):\n",
    "        average_accuracy += accuracy_scores[i]\n",
    "    average_accuracy /= score_amount\n",
    "    if (DEBUG_MODE):\n",
    "        print ('The average accuracy is {}'.format(average_accuracy))\n",
    "    print('{}#{}#{}'.format(avg_difference_between_methods, str(end - start), average_accuracy))\n",
    "\n",
    "\n",
    "def create_or_load_classifiers(chosen_classifier):\n",
    "    '''\n",
    "    Attempts to load all classifiers according to the chosen classifier.\n",
    "    Generates those that don't exist.\n",
    "    Returns the path where models can be found.\n",
    "    '''\n",
    "    # Base path for classifier persistence.\n",
    "    # TODO maybe make ./models/ dir configurable.\n",
    "    model_base_path = './models/' + chosen_classifier + '/' + str(task_amount) + 'x' + str(machine_amount) \\\n",
    "        + '-' + str(task_heterogeneity) + str(machine_heterogeneity) \\\n",
    "        + str(consistency_type) + '/'\n",
    "    if chosen_classifier == CLASSIFIER_STRING_ANN:\n",
    "        if USING_ENTIRE_ETC:\n",
    "            dimension = task_amount * machine_amount\n",
    "            # Reference: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "            ns = 600  # Amount of training examples.\n",
    "            ni = dimension\n",
    "            no = 1  # Amount of output neurons.\n",
    "            alpha = 2\n",
    "            # int(math.ceil(ns / (alpha * (ni + no)))) # Con 2 hardcodeado parece aprender mejor\n",
    "            hidden_layer_amount = 2\n",
    "            # Each hidden layer has an intermediate amount of neurons (between the neuron amount\n",
    "            # present in the output layer and the input layer).\n",
    "            # A tuple is generated to set up the MLPClassifier.\n",
    "            hidden_layer_neuron_amount = tuple([int(math.ceil((task_amount - no) / 2))]\n",
    "                                               * hidden_layer_amount)\n",
    "        else:\n",
    "            \n",
    "            dimension = machine_amount\n",
    "            # Reference: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "            ns = 600  # Amount of training examples.\n",
    "            ni = dimension\n",
    "            no = 1  # Amount of output neurons.\n",
    "            alpha = 2\n",
    "            # int(math.ceil(ns / (alpha * (ni + no)))) # Con 2 hardcodeado parece aprender mejor\n",
    "            hidden_layer_amount = 2\n",
    "            # Each hidden layer has an intermediate amount of neurons (between the neuron amount\n",
    "            # present in the output layer and the input layer).\n",
    "            # A tuple is generated to set up the MLPClassifier.\n",
    "            hidden_layer_neuron_amount = tuple([int(math.ceil((ni - no) / 2))]\n",
    "                                               * hidden_layer_amount)\n",
    "    elif chosen_classifier == CLASSIFIER_STRING_SVM:\n",
    "        # No mandatory config for SVC method.\n",
    "        pass\n",
    "    # TODO maybe specify classifier configuration along with this (so as to not specify something that might already exist)\n",
    "    # Attempt to load models, or just create them and store them in memory (classifiers array).\n",
    "    for i in range(0, task_amount):\n",
    "        try:\n",
    "            classifier = joblib.load(getModelPathStr(model_base_path, chosen_classifier, i))\n",
    "        except Exception:\n",
    "            if (DEBUG_MODE):\n",
    "                print('The classifier for output ' +\n",
    "                      str(i) + ' didn\\'t exist.')\n",
    "            if chosen_classifier == CLASSIFIER_STRING_ANN:\n",
    "                classifier = MLPClassifier(solver='lbfgs', alpha=1e-2,\n",
    "                                           hidden_layer_sizes=hidden_layer_neuron_amount, random_state=1)\n",
    "            elif chosen_classifier == CLASSIFIER_STRING_SVM:\n",
    "                classifier = svm.SVC()\n",
    "        finally:\n",
    "            # Append classifier to classifier list (in memory).\n",
    "            classifiers.append(classifier)\n",
    "    return model_base_path\n",
    "\n",
    "def getModelPathStr(model_base_path, chosen_classifier, classifier_index):\n",
    "    '''\n",
    "    Returns a string with the path where models live.\n",
    "    '''\n",
    "    return model_base_path + MODEL_FILE_PREFIX + chosen_classifier + str(classifier_index) + MODEL_FILE_EXTENSION\n",
    "\n",
    "# TODO move the following to some utils module.\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
