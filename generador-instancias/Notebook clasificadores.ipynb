{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "import parser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import generar_jobs\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem parameters.\n",
    "# TODO receive as parameters\n",
    "task_amount = 128\n",
    "machine_amount = 4\n",
    "task_heterogeneity = 0\n",
    "machine_heterogeneity = 0\n",
    "consistency_type = 0\n",
    "accuracy_scores = []\n",
    "classifiers = []\n",
    "# Classifier configuration.\n",
    "CLASSIFIER_STRING_ANN = 'ann'\n",
    "CLASSIFIER_STRING_SVM = 'svm'\n",
    "classifier_types = [CLASSIFIER_STRING_ANN, CLASSIFIER_STRING_SVM]\n",
    "current_classifier_index = 0 # Only modify this.\n",
    "current_classifier_str = classifier_types[current_classifier_index]\n",
    "# Base path for classifier persistence.\n",
    "model_base_path = './models/' + current_classifier_str + '/' + str(task_amount) + 'x' + str(machine_amount) \\\n",
    "    + '-' + str(task_heterogeneity) + str(machine_heterogeneity) \\\n",
    "    + str(consistency_type) + '/'\n",
    "baseDir = './data-processed/' + str(task_amount) + 'x' \\\n",
    "    + str(machine_amount) + '-' + str(task_heterogeneity) \\\n",
    "    + str(machine_heterogeneity) + str(consistency_type) + '/'\n",
    "model_file_prefix = 'clf-' + current_classifier_str\n",
    "model_file_extension = '.pkl'\n",
    "\n",
    "if current_classifier_str == CLASSIFIER_STRING_ANN:\n",
    "    dimension = task_amount * machine_amount\n",
    "    # Reference: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "    ns = 600  # Amount of training examples.\n",
    "    ni = dimension\n",
    "    no = 1  # Amount of output neurons.\n",
    "    alpha = 2\n",
    "    hidden_layer_amount = 2 #int(math.ceil(ns / (alpha * (ni + no)))) # Con 2 hardcodeado parece aprender mejor\n",
    "    # Each hidden layer has an intermediate amount of neurons (between the neuron amount\n",
    "    # present in the output layer and the input layer).\n",
    "    # A tuple is generated to set up the MLPClassifier.\n",
    "    hidden_layer_neuron_amount = tuple([int(math.ceil((task_amount - no) / 2))]\n",
    "                                       * hidden_layer_amount)  \n",
    "elif current_classifier_str == CLASSIFIER_STRING_SVM:\n",
    "    # No config necessary for SVC method.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier for output 14 didn't exist.\n",
      "The classifier for output 15 didn't exist.\n",
      "The classifier for output 16 didn't exist.\n",
      "The classifier for output 17 didn't exist.\n",
      "The classifier for output 18 didn't exist.\n",
      "The classifier for output 19 didn't exist.\n",
      "The classifier for output 20 didn't exist.\n",
      "The classifier for output 21 didn't exist.\n",
      "The classifier for output 22 didn't exist.\n",
      "The classifier for output 23 didn't exist.\n",
      "The classifier for output 24 didn't exist.\n",
      "The classifier for output 25 didn't exist.\n",
      "The classifier for output 26 didn't exist.\n",
      "The classifier for output 27 didn't exist.\n",
      "The classifier for output 28 didn't exist.\n",
      "The classifier for output 29 didn't exist.\n",
      "The classifier for output 30 didn't exist.\n",
      "The classifier for output 31 didn't exist.\n",
      "The classifier for output 32 didn't exist.\n",
      "The classifier for output 33 didn't exist.\n",
      "The classifier for output 34 didn't exist.\n",
      "The classifier for output 35 didn't exist.\n",
      "The classifier for output 36 didn't exist.\n",
      "The classifier for output 37 didn't exist.\n",
      "The classifier for output 38 didn't exist.\n",
      "The classifier for output 39 didn't exist.\n",
      "The classifier for output 40 didn't exist.\n",
      "The classifier for output 41 didn't exist.\n",
      "The classifier for output 42 didn't exist.\n",
      "The classifier for output 43 didn't exist.\n",
      "The classifier for output 44 didn't exist.\n",
      "The classifier for output 45 didn't exist.\n",
      "The classifier for output 46 didn't exist.\n",
      "The classifier for output 47 didn't exist.\n",
      "The classifier for output 48 didn't exist.\n",
      "The classifier for output 49 didn't exist.\n",
      "The classifier for output 50 didn't exist.\n",
      "The classifier for output 51 didn't exist.\n",
      "The classifier for output 52 didn't exist.\n",
      "The classifier for output 53 didn't exist.\n",
      "The classifier for output 54 didn't exist.\n",
      "The classifier for output 55 didn't exist.\n",
      "The classifier for output 56 didn't exist.\n",
      "The classifier for output 57 didn't exist.\n",
      "The classifier for output 58 didn't exist.\n",
      "The classifier for output 59 didn't exist.\n",
      "The classifier for output 60 didn't exist.\n",
      "The classifier for output 61 didn't exist.\n",
      "The classifier for output 62 didn't exist.\n",
      "The classifier for output 63 didn't exist.\n",
      "The classifier for output 64 didn't exist.\n",
      "The classifier for output 65 didn't exist.\n",
      "The classifier for output 66 didn't exist.\n",
      "The classifier for output 67 didn't exist.\n",
      "The classifier for output 68 didn't exist.\n",
      "The classifier for output 69 didn't exist.\n",
      "The classifier for output 70 didn't exist.\n",
      "The classifier for output 71 didn't exist.\n",
      "The classifier for output 72 didn't exist.\n",
      "The classifier for output 73 didn't exist.\n",
      "The classifier for output 74 didn't exist.\n",
      "The classifier for output 75 didn't exist.\n",
      "The classifier for output 76 didn't exist.\n",
      "The classifier for output 77 didn't exist.\n",
      "The classifier for output 78 didn't exist.\n",
      "The classifier for output 79 didn't exist.\n",
      "The classifier for output 80 didn't exist.\n",
      "The classifier for output 81 didn't exist.\n",
      "The classifier for output 82 didn't exist.\n",
      "The classifier for output 83 didn't exist.\n",
      "The classifier for output 84 didn't exist.\n",
      "The classifier for output 85 didn't exist.\n",
      "The classifier for output 86 didn't exist.\n",
      "The classifier for output 87 didn't exist.\n",
      "The classifier for output 88 didn't exist.\n",
      "The classifier for output 89 didn't exist.\n",
      "The classifier for output 90 didn't exist.\n",
      "The classifier for output 91 didn't exist.\n",
      "The classifier for output 92 didn't exist.\n",
      "The classifier for output 93 didn't exist.\n",
      "The classifier for output 94 didn't exist.\n",
      "The classifier for output 95 didn't exist.\n",
      "The classifier for output 96 didn't exist.\n",
      "The classifier for output 97 didn't exist.\n",
      "The classifier for output 98 didn't exist.\n",
      "The classifier for output 99 didn't exist.\n",
      "The classifier for output 100 didn't exist.\n",
      "The classifier for output 101 didn't exist.\n",
      "The classifier for output 102 didn't exist.\n",
      "The classifier for output 103 didn't exist.\n",
      "The classifier for output 104 didn't exist.\n",
      "The classifier for output 105 didn't exist.\n",
      "The classifier for output 106 didn't exist.\n",
      "The classifier for output 107 didn't exist.\n",
      "The classifier for output 108 didn't exist.\n",
      "The classifier for output 109 didn't exist.\n",
      "The classifier for output 110 didn't exist.\n",
      "The classifier for output 111 didn't exist.\n",
      "The classifier for output 112 didn't exist.\n",
      "The classifier for output 113 didn't exist.\n",
      "The classifier for output 114 didn't exist.\n",
      "The classifier for output 115 didn't exist.\n",
      "The classifier for output 116 didn't exist.\n",
      "The classifier for output 117 didn't exist.\n",
      "The classifier for output 118 didn't exist.\n",
      "The classifier for output 119 didn't exist.\n",
      "The classifier for output 120 didn't exist.\n",
      "The classifier for output 121 didn't exist.\n",
      "The classifier for output 122 didn't exist.\n",
      "The classifier for output 123 didn't exist.\n",
      "The classifier for output 124 didn't exist.\n",
      "The classifier for output 125 didn't exist.\n",
      "The classifier for output 126 didn't exist.\n",
      "The classifier for output 127 didn't exist.\n"
     ]
    }
   ],
   "source": [
    "# Generate or load the classifiers (if they already exist).\n",
    "# TODO maybe specify classifier configuration along with this (so as to not specify something that might already exist)\n",
    "for i in range(0, task_amount):\n",
    "    try:\n",
    "        classifier = joblib.load(model_base_path + model_file_prefix + str(i) \\\n",
    "                                 + model_file_extension)\n",
    "    except Exception:\n",
    "        print('The classifier for output ' + str(i) + ' didn\\'t exist.')\n",
    "        if current_classifier_str == CLASSIFIER_STRING_ANN:\n",
    "            classifier = MLPClassifier(solver='lbfgs', alpha=1e-2, \n",
    "                hidden_layer_sizes=hidden_layer_neuron_amount, random_state=1)\n",
    "        elif current_classifier_str == CLASSIFIER_STRING_SVM:\n",
    "            classifier = svm.SVC()\n",
    "    finally:\n",
    "        # Append classifier to classifier list (in memory).\n",
    "        classifiers.append(classifier)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena cada clasificador, y para cada uno se hace lo siguiente (post-entrenamiento)\n",
    "* Se evalua la accuracy usando el training set\n",
    "* Se recorre cada instancia del training set y se calcula el makespan que aporta el clasificador correspondiente\n",
    "    * O sea que se va a obtener un vector, donde cada entrada es el makespan para una instancia de entrenamiento distinta\n",
    "    * Como este vector eventualmente se va a obtener para cada clasificador, se va a tener una matriz, donde el primer indice accede a un clasificador, y el segundo a un makespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier 0...\n",
      "    Doing makespan stuff...\n",
      "    Classifier accuracy: 0.34\n",
      "Training classifier 1...\n",
      "    Doing makespan stuff...\n",
      "    Classifier accuracy: 0.35\n",
      "Training classifier 2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3e428567be28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mTEST_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseDir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m \u001b[0;31m# Test file for current classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    643\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    264\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5383\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5384\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5386\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   5693\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5694\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[0;32m-> 5695\u001b[0;31m                                 raise_cast_failure=False)\n\u001b[0m\u001b[1;32m   5696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marccio/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2864\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2866\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2867\u001b[0m             \u001b[0;31m# don't coerce Index types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2868\u001b[0m             \u001b[0;31m# e.g. indexes can have different conversions (so don't fast path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# No threading version\n",
    "start = time.time()\n",
    "# Each index corresponds to an instance\n",
    "makespan_instance_machines_heuristic = []\n",
    "makespan_instance_machines_prediction = []\n",
    "SCALE_DATA = True\n",
    "# Within each index, there'll be an array of machine_amount elements, in which each element\n",
    "# is the time during which each machine is running\n",
    "# Something along the lines of [[10,20,9,40], [99,88,22,11], ..., [10,9,21,35]]\n",
    "for i in range(0, task_amount): # For each task/classifier\n",
    "    print(\"Training classifier \" + str(i) + \"...\")\n",
    "    # Data is loaded.\n",
    "    TRAINING_FILE = baseDir + 'training/' + str(i) + '.csv' # Training file for current classifier\n",
    "    TEST_FILE = baseDir + 'test/' + str(i) + '.csv' # Test file for current classifier\n",
    "    training_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "    test_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "    \n",
    "    \n",
    "    # Create dataframe for data and separate target.\n",
    "    df_training = pd.DataFrame(training_set)\n",
    "    df_training_input = df_training.iloc[:, :-1] \n",
    "    df_training_output = df_training.iloc[:, -1] #y_training\n",
    "    # print(\"##### BEFORE #####\")\n",
    "    # print(df_training_input)\n",
    "    if SCALE_DATA:\n",
    "        # Scale data because http://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use\n",
    "        scaler = StandardScaler()  \n",
    "        # Don't cheat - fit only on training data\n",
    "        scaler.fit(df_training_input)\n",
    "        # Reconvert input training data to dataframe after scaling (which converts it to an array of arrays).\n",
    "        df_training_input = pd.DataFrame(scaler.transform(df_training_input))\n",
    "        # print(\"##### AFTER #####\")\n",
    "        # print(df_training_input)\n",
    "\n",
    "    # print(\"#############\")\n",
    "    # print(df_training)\n",
    "    # y_training = df_training.iloc[:, -1]\n",
    "    # Validation/testing data is loaded.\n",
    "    df_test = pd.DataFrame(test_set)\n",
    "    df_test_input = df_test.iloc[:, :-1]\n",
    "    df_test_output = df_test.iloc[:, -1] #y_test\n",
    "    \n",
    "    if SCALE_DATA:\n",
    "        scaler = StandardScaler()  \n",
    "        scaler.fit(df_test_input)\n",
    "        # Scale test data.\n",
    "        df_test_input = pd.DataFrame(scaler.transform(df_test_input))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Classifier is trained using the data.\n",
    "    classifiers[i].fit(df_training_input, df_training_output)\n",
    "    # Classifier directory is generated if it doesn't exist.\n",
    "    generar_jobs.generate_dir(model_base_path)\n",
    "    # Classifier is persisted.\n",
    "    joblib.dump(classifiers[i], model_base_path + model_file_prefix + str(i) \\\n",
    "                + model_file_extension)\n",
    "    # Classifier accuracy is determined using test data.\n",
    "    results = []\n",
    "    # Go through every test instance manually to calculate makespan for each\n",
    "    # problem-classifier/task pair\n",
    "    current_task_index = i * machine_amount # Column index within etc matrix\n",
    "    print(\"    Doing makespan stuff...\")\n",
    "    test_instance_amount = len(df_test)\n",
    "    for j in range(0, test_instance_amount): # For every validation instance\n",
    "#         # df_test.iloc[j] is an ETC matrix + the corresponding classification for one task\n",
    "#         problem_instance = df_test.iloc[j]\n",
    "#         etc_matrix = problem_instance[:-1]\n",
    "#         classification_heuristic = float(problem_instance[-1:]) # float format\n",
    "        etc_matrix = df_test_input.iloc[[j]] # etc_matrix for j problem instance\n",
    "#         print(\"########## DF_TEST_INPUT ##########\")\n",
    "#         print(df_test_input)\n",
    "#         print(\"Current etc_matrix is: \" + str(etc_matrix))\n",
    "        classification_heuristic = float(df_test_output[j])\n",
    "#         print(\"Classification is: \" + str(classification_heuristic))\n",
    "        # Every test example is classified, and its classification is appended\n",
    "        # to a results array.\n",
    "        # Make prediction for current problem instance or etc matrix\n",
    "        prediction_pandas = float(classifiers[i].predict(etc_matrix.values.reshape(1, -1)))\n",
    "        results.append(prediction_pandas)\n",
    "        prediction = float(prediction_pandas) # To work in floats\n",
    "        #os.write(1, 'Prediction pandas: ' + str(prediction_pandas) + ', Prediction: ' + str(prediction) + '\\n');\n",
    "#         print('Prediction pandas: ' + str(prediction_pandas) + ', Prediction: ' + str(prediction));\n",
    "\n",
    "        # TODO ver que pasa con las dimensiones de etc_matrix, porque no agarra bien la subrow\n",
    "        sub_row_for_current_task = etc_matrix[current_task_index:current_task_index + machine_amount]\n",
    "        os.write(1, \"########### ETC_MATRIX:\\n\" + str(etc_matrix))\n",
    "        os.write(1, \"########### SUBROW:\\n\" + str(sub_row_for_current_task))\n",
    "        # Makespan value for prediction (tiempo que me incurre hacer la prediccion)\n",
    "        current_makespan_prediction = sub_row_for_current_task[current_task_index + prediction]\n",
    "        # Makespan value for heuristic (tiempo en el que incurre la heuristica al hacer esta asignacion)\n",
    "        current_makespan_heuristic = sub_row_for_current_task[current_task_index + classification_heuristic]\n",
    "        if len(makespan_instance_machines_prediction) <= j: # Si todavia no tengo entrada para esta instancia\n",
    "            makespan_instance_machines_prediction.append([0.0] * machine_amount) # Inicializo entrada para esta instancia, con el makespan\n",
    "            makespan_instance_machines_heuristic.append([0.0] * machine_amount)\n",
    "            # de cada maquina\n",
    "#         print(\"Makespan pred: \\n\" + str(current_makespan_prediction) + \"\\nHeuristic: \" + str(current_makespan_heuristic))\n",
    "        makespan_instance_machines_prediction[j][int(prediction)] += current_makespan_prediction\n",
    "        makespan_instance_machines_heuristic[j][int(classification_heuristic)] += current_makespan_heuristic\n",
    "    # Actual results are compared to expected values.\n",
    "    accuracy = accuracy_score(df_test_output, results)\n",
    "    print(\"    Classifier accuracy: \" + str(accuracy))\n",
    "    # Calculated accuracy is added to accuracies list.\n",
    "    accuracy_scores.append(accuracy)\n",
    "end = time.time()\n",
    "print('The execution took ' + str(end - start) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 7, dtype: float64),\n",
       "  Series([], Name: 14, dtype: float64),\n",
       "  Series([], Name: 10, dtype: float64)],\n",
       " [1   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 22, dtype: float64),\n",
       "  Series([], Name: 14, dtype: float64),\n",
       "  Series([], Name: 17, dtype: float64)],\n",
       " [2   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 35, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 66, dtype: float64)],\n",
       " [3   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 30, dtype: float64),\n",
       "  Series([], Name: 100, dtype: float64)],\n",
       " [4   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 24, dtype: float64),\n",
       "  Series([], Name: 14, dtype: float64)],\n",
       " [Series([], Name: 22, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  5   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 70, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  6   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 13, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  7   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 13, dtype: float64)],\n",
       " [Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 22, dtype: float64),\n",
       "  8   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [9   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 9, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 76, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64), 10   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 40, dtype: float64), Series([], Name: 53, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64), 11   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 8, dtype: float64), Series([], Name: 33, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 48, dtype: float64),\n",
       "  Series([], Name: 25, dtype: float64),\n",
       "  12   NaN\n",
       "  Name: 1, dtype: float64],\n",
       " [13   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 24, dtype: float64),\n",
       "  Series([], Name: 61, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64), 14   NaN\n",
       "  Name: 3, dtype: float64, Series([], Name: 23, dtype: float64), Series([], Name: 85, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  15   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 67, dtype: float64)],\n",
       " [16   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 23, dtype: float64),\n",
       "  Series([], Name: 92, dtype: float64),\n",
       "  Series([], Name: 31, dtype: float64)],\n",
       " [17   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 9, dtype: float64),\n",
       "  Series([], Name: 51, dtype: float64)],\n",
       " [Series([], Name: 7, dtype: float64),\n",
       "  Series([], Name: 24, dtype: float64),\n",
       "  18   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 131, dtype: float64)],\n",
       " [Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 21, dtype: float64),\n",
       "  Series([], Name: 39, dtype: float64),\n",
       "  19   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [20   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 21, dtype: float64),\n",
       "  Series([], Name: 26, dtype: float64)],\n",
       " [21   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 40, dtype: float64),\n",
       "  Series([], Name: 32, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 24, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  22   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [Series([], Name: 6, dtype: float64), 23   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 9, dtype: float64), Series([], Name: 28, dtype: float64)],\n",
       " [24   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 25, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 13, dtype: float64)],\n",
       " [Series([], Name: 20, dtype: float64), 25   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 4, dtype: float64), Series([], Name: 26, dtype: float64)],\n",
       " [Series([], Name: 6, dtype: float64), 26   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 36, dtype: float64), Series([], Name: 23, dtype: float64)],\n",
       " [Series([], Name: 8, dtype: float64), 27   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 60, dtype: float64), Series([], Name: 4, dtype: float64)],\n",
       " [Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 10, dtype: float64),\n",
       "  28   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [29   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  Series([], Name: 21, dtype: float64)],\n",
       " [Series([], Name: 7, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  30   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [31   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 70, dtype: float64)],\n",
       " [Series([], Name: 7, dtype: float64),\n",
       "  Series([], Name: 51, dtype: float64),\n",
       "  32   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 28, dtype: float64)],\n",
       " [33   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 68, dtype: float64)],\n",
       " [34   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 11, dtype: float64),\n",
       "  Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 15, dtype: float64)],\n",
       " [Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  35   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 7, dtype: float64)],\n",
       " [Series([], Name: 9, dtype: float64),\n",
       "  Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 19, dtype: float64),\n",
       "  36   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [37   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  Series([], Name: 12, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64), 38   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 16, dtype: float64), Series([], Name: 28, dtype: float64)],\n",
       " [Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  39   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 29, dtype: float64)],\n",
       " [Series([], Name: 14, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  40   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 4, dtype: float64)],\n",
       " [41   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 32, dtype: float64),\n",
       "  Series([], Name: 19, dtype: float64),\n",
       "  Series([], Name: 98, dtype: float64)],\n",
       " [42   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 36, dtype: float64)],\n",
       " [Series([], Name: 7, dtype: float64),\n",
       "  Series([], Name: 15, dtype: float64),\n",
       "  Series([], Name: 45, dtype: float64),\n",
       "  43   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [Series([], Name: 17, dtype: float64), 44   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 4, dtype: float64), Series([], Name: 13, dtype: float64)],\n",
       " [Series([], Name: 8, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  45   NaN\n",
       "  Name: 1, dtype: float64],\n",
       " [46   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 36, dtype: float64),\n",
       "  Series([], Name: 26, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64), 47   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 16, dtype: float64), Series([], Name: 24, dtype: float64)],\n",
       " [Series([], Name: 9, dtype: float64), 48   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 44, dtype: float64), Series([], Name: 4, dtype: float64)],\n",
       " [Series([], Name: 12, dtype: float64), 49   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 6, dtype: float64), Series([], Name: 19, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64), 50   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 65, dtype: float64), Series([], Name: 8, dtype: float64)],\n",
       " [Series([], Name: 8, dtype: float64), 51   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 4, dtype: float64), Series([], Name: 45, dtype: float64)],\n",
       " [52   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 40, dtype: float64),\n",
       "  Series([], Name: 28, dtype: float64),\n",
       "  Series([], Name: 5, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64), 53   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 52, dtype: float64), Series([], Name: 9, dtype: float64)],\n",
       " [Series([], Name: 6, dtype: float64), 54   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 34, dtype: float64), Series([], Name: 16, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64), 55   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 8, dtype: float64), Series([], Name: 15, dtype: float64)],\n",
       " [56   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  Series([], Name: 54, dtype: float64),\n",
       "  Series([], Name: 12, dtype: float64)],\n",
       " [Series([], Name: 11, dtype: float64), 57   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 4, dtype: float64), Series([], Name: 48, dtype: float64)],\n",
       " [58   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 20, dtype: float64),\n",
       "  Series([], Name: 7, dtype: float64),\n",
       "  Series([], Name: 68, dtype: float64)],\n",
       " [59   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 40, dtype: float64),\n",
       "  Series([], Name: 20, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64)],\n",
       " [60   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 32, dtype: float64),\n",
       "  Series([], Name: 9, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64)],\n",
       " [61   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  Series([], Name: 30, dtype: float64),\n",
       "  Series([], Name: 33, dtype: float64)],\n",
       " [62   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 24, dtype: float64),\n",
       "  Series([], Name: 20, dtype: float64),\n",
       "  Series([], Name: 33, dtype: float64)],\n",
       " [63   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 15, dtype: float64),\n",
       "  Series([], Name: 53, dtype: float64),\n",
       "  Series([], Name: 38, dtype: float64)],\n",
       " [64   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  Series([], Name: 10, dtype: float64)],\n",
       " [65   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  Series([], Name: 14, dtype: float64),\n",
       "  Series([], Name: 88, dtype: float64)],\n",
       " [66   NaN\n",
       "  Name: 3, dtype: float64,\n",
       "  Series([], Name: 22, dtype: float64),\n",
       "  Series([], Name: 35, dtype: float64),\n",
       "  Series([], Name: 38, dtype: float64)],\n",
       " [67   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 89, dtype: float64),\n",
       "  Series([], Name: 66, dtype: float64)],\n",
       " [68   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  Series([], Name: 20, dtype: float64),\n",
       "  Series([], Name: 5, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 44, dtype: float64),\n",
       "  69   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 38, dtype: float64)],\n",
       " [70   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 59, dtype: float64),\n",
       "  Series([], Name: 92, dtype: float64)],\n",
       " [Series([], Name: 7, dtype: float64), 71   NaN\n",
       "  Name: 3, dtype: float64, Series([], Name: 49, dtype: float64), Series([], Name: 21, dtype: float64)],\n",
       " [72   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 20, dtype: float64),\n",
       "  Series([], Name: 19, dtype: float64),\n",
       "  Series([], Name: 6, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  73   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 10, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64), 74   NaN\n",
       "  Name: 0, dtype: float64, Series([], Name: 26, dtype: float64), Series([], Name: 126, dtype: float64)],\n",
       " [75   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 36, dtype: float64),\n",
       "  Series([], Name: 24, dtype: float64),\n",
       "  Series([], Name: 7, dtype: float64)],\n",
       " [Series([], Name: 8, dtype: float64),\n",
       "  Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 29, dtype: float64),\n",
       "  76   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [Series([], Name: 8, dtype: float64), 77   NaN\n",
       "  Name: 1, dtype: float64, Series([], Name: 4, dtype: float64), Series([], Name: 62, dtype: float64)],\n",
       " [78   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 14, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 58, dtype: float64)],\n",
       " [79   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 19, dtype: float64),\n",
       "  Series([], Name: 51, dtype: float64),\n",
       "  Series([], Name: 33, dtype: float64)],\n",
       " [Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 42, dtype: float64),\n",
       "  Series([], Name: 25, dtype: float64),\n",
       "  80   NaN\n",
       "  Name: 3, dtype: float64],\n",
       " [81   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 45, dtype: float64),\n",
       "  Series([], Name: 7, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 39, dtype: float64),\n",
       "  82   NaN\n",
       "  Name: 1, dtype: float64],\n",
       " [83   NaN\n",
       "  Name: 2, dtype: float64,\n",
       "  Series([], Name: 20, dtype: float64),\n",
       "  Series([], Name: 17, dtype: float64),\n",
       "  Series([], Name: 7, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  84   NaN\n",
       "  Name: 1, dtype: float64],\n",
       " [85   NaN\n",
       "  Name: 3, dtype: float64,\n",
       "  Series([], Name: 26, dtype: float64),\n",
       "  Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 89, dtype: float64)],\n",
       " [86   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 15, dtype: float64),\n",
       "  Series([], Name: 32, dtype: float64),\n",
       "  Series([], Name: 39, dtype: float64)],\n",
       " [87   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 25, dtype: float64),\n",
       "  Series([], Name: 88, dtype: float64)],\n",
       " [Series([], Name: 4, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  88   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 27, dtype: float64)],\n",
       " [89   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 27, dtype: float64),\n",
       "  Series([], Name: 16, dtype: float64),\n",
       "  Series([], Name: 35, dtype: float64)],\n",
       " [90   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 24, dtype: float64),\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 5, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 9, dtype: float64),\n",
       "  91   NaN\n",
       "  Name: 1, dtype: float64,\n",
       "  Series([], Name: 12, dtype: float64)],\n",
       " [92   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 39, dtype: float64),\n",
       "  Series([], Name: 20, dtype: float64),\n",
       "  Series([], Name: 28, dtype: float64)],\n",
       " [93   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  Series([], Name: 20, dtype: float64)],\n",
       " [Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 12, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64),\n",
       "  94   NaN\n",
       "  Name: 1, dtype: float64],\n",
       " [Series([], Name: 6, dtype: float64),\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 22, dtype: float64),\n",
       "  95   NaN\n",
       "  Name: 2, dtype: float64],\n",
       " [Series([], Name: 4, dtype: float64), 96   NaN\n",
       "  Name: 3, dtype: float64, Series([], Name: 40, dtype: float64), Series([], Name: 48, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64), 97   NaN\n",
       "  Name: 2, dtype: float64, Series([], Name: 52, dtype: float64), Series([], Name: 66, dtype: float64)],\n",
       " [Series([], Name: 5, dtype: float64),\n",
       "  Series([], Name: 48, dtype: float64),\n",
       "  Series([], Name: 25, dtype: float64),\n",
       "  98   NaN\n",
       "  Name: 0, dtype: float64],\n",
       " [99   NaN\n",
       "  Name: 0, dtype: float64,\n",
       "  Series([], Name: 13, dtype: float64),\n",
       "  Series([], Name: 38, dtype: float64),\n",
       "  Series([], Name: 8, dtype: float64)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Array that holds makespan values for the prediction.\n",
    "# makespan_prediction = []\n",
    "# for i in range(0, len(makespan_instance_machines_prediction)):\n",
    "#     makespan_prediction.append(np.max(makespan_instance_machines_prediction[i]))\n",
    "# # Array that holds makespan values for the heuristic\n",
    "# makespan_heuristic = []\n",
    "# for i in range(0, len(makespan_instance_machines_heuristic)):\n",
    "#     makespan_heuristic.append(np.max(makespan_instance_machines_heuristic[i]))\n",
    "# # Array that holds the difference between heuristic and prediction makespan.\n",
    "# makespan_diff = []\n",
    "# for i in range(0, len(makespan_prediction)):\n",
    "#     makespan_diff.append(makespan_prediction[i] - makespan_heuristic[i])\n",
    "# # Calculate average difference between methods.\n",
    "# avg_difference_between_methods = np.mean(makespan_diff)\n",
    "# print('Average difference between techniques: ' + str(avg_difference_between_methods))\n",
    "# if avg_difference_between_methods > 0:\n",
    "#     print('The heuristic works better on average')\n",
    "# elif avg_difference_between_methods < 0:\n",
    "#     print('Savant works better on average')\n",
    "# else:\n",
    "#     print('Both techniques work equivalently on average')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO update this to include makespan calculation\n",
    "\n",
    "# # Multithreading version\n",
    "# import os\n",
    "\n",
    "# def train_and_persist_classifier(classifier_index):\n",
    "#     # Data is loaded.\n",
    "#     TRAINING_FILE = baseDir + 'training/' + str(classifier_index) + '.csv'\n",
    "#     TEST_FILE = baseDir + 'test/' + str(classifier_index) + '.csv'\n",
    "#     training_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "#     test_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "#     # Create dataframe for data and separate target.\n",
    "#     df_training = pd.DataFrame(training_set)\n",
    "#     y_training = df_training.iloc[:, -1]\n",
    "#     # Validation/testing data is loaded.\n",
    "#     df_test = pd.DataFrame(test_set)\n",
    "#     y_test = df_test.iloc[:, -1]\n",
    "#     # Classifier is trained using the data.\n",
    "#     classifiers[classifier_index].fit(df_training.iloc[:, :-1], y_training)\n",
    "#     # Classifier directory is generated if it doesn't exist.\n",
    "#     generar_jobs.generate_dir(model_base_path)\n",
    "#     # Classifier is persisted.\n",
    "#     joblib.dump(classifiers[classifier_index], model_base_path + model_file_prefix + str(classifier_index) \\\n",
    "#                 + model_file_extension)\n",
    "#     # Classifier accuracy is determined using test data.\n",
    "#     results = []\n",
    "#     for i in range(0, len(df_test)):\n",
    "#         # Every test example is classified, and its classification is appended\n",
    "#         # to a results array.\n",
    "#         results.append(classifiers[classifier_index].predict(\n",
    "#             df_test.iloc[i][:-1].values.reshape(1, -1)))\n",
    "#     # Actual results are compared to expected values.\n",
    "#     accuracy = accuracy_score(y_test, results)\n",
    "#     os.write(1,'Classifier ' + str(classifier_index) + ':\\n') # Print directly to console\n",
    "#     os.write(1, 'Accuracy: ' + str(accuracy) + ', ') # Print directly to console\n",
    "#     # Calculated accuracy is added to accuracies list.\n",
    "#     accuracy_scores.append(accuracy)\n",
    "# #     os.write(1, 'Training of classifier ' + str(classifier_index) + ' finished.\\n') \n",
    "#     return\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "# import multiprocessing\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     ##### VERSION 1 #####\n",
    "# #     jobs = []\n",
    "# #     for i in range(0, task_amount):\n",
    "# #         print('Starting training of classifier ' + str(i))\n",
    "# #         p = multiprocessing.Process(target=train_and_persist_classifier(i))\n",
    "# #         jobs.append(p)\n",
    "# #         p.start()\n",
    "#     ##### END VERSION 1 #####\n",
    "#     ##### VERSION 2 #####\n",
    "#     start = time.time()\n",
    "#     num_cores = multiprocessing.cpu_count() * 4\n",
    "#     # For every task, train a classifier.\n",
    "#     Parallel(n_jobs=num_cores)(delayed(train_and_persist_classifier)(i) for i in range(0,task_amount))\n",
    "#     end = time.time()\n",
    "#     print('The execution took ' + str(end - start) + ' seconds')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average accuracy (for all classifiers) is calculated (nothing to do with threading).\n",
    "promedio = 0.\n",
    "score_amount = len(accuracy_scores)\n",
    "for i in range(0, score_amount):\n",
    "    promedio += accuracy_scores[i]\n",
    "promedio /= score_amount\n",
    "print ('The average accuracy is {}'.format(promedio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier 0...\n",
      "##### BEFORE #####\n",
      "        0       1       2       3       4       5       6       7       8    \\\n",
      "0    180.80  242.71  495.44  526.07  125.71  271.89  274.12  373.41    2.33   \n",
      "1     12.73   25.58  439.26  676.48   91.42  110.97  168.78  321.79   67.61   \n",
      "2    306.20  355.49  377.72  462.72   42.92  106.53  545.97  757.45   19.48   \n",
      "3    155.29  238.72  274.79  466.53    9.52   36.11   53.07   65.96   75.63   \n",
      "4      9.20   82.30  152.59  197.13   37.05  105.36  180.67  230.68  115.33   \n",
      "5    122.52  164.22  201.54  218.26   62.69  342.09  377.68  497.12    0.68   \n",
      "6     34.61   41.60   50.97   67.81  267.76  400.21  438.12  445.82   18.99   \n",
      "7    135.06  432.79  503.92  799.80  107.89  215.49  405.02  929.46   61.02   \n",
      "8    155.96  245.41  426.66  706.89   46.77   92.23   92.98  128.60  182.87   \n",
      "9    352.45  388.65  537.12  654.71   38.96   68.38   87.11  173.51  160.33   \n",
      "10   129.75  146.74  281.30  383.85   36.69   54.80  350.68  500.77    2.76   \n",
      "11   180.57  213.19  310.09  430.77   77.47  384.04  571.36  750.60  169.89   \n",
      "12    44.88   49.73  148.15  212.33    1.52    5.00    8.81   12.14   42.06   \n",
      "13    70.23   86.15  118.69  167.98   20.26  159.91  167.14  221.04   86.30   \n",
      "14     4.46    5.35   27.20   38.26  154.47  254.37  258.58  260.56  198.24   \n",
      "15   331.53  398.25  514.71  724.31   52.06  132.49  295.53  641.16    0.95   \n",
      "16    13.90   75.42  333.59  386.60  283.39  504.35  517.62  721.52   13.26   \n",
      "17   125.22  271.99  325.62  561.32    6.57   18.86   19.96   41.89    4.41   \n",
      "18   213.45  311.18  485.38  517.05   19.71   23.51  175.45  258.61  193.73   \n",
      "19   128.63  157.95  172.17  247.47   31.67  239.13  360.55  501.51   62.85   \n",
      "20    13.66   85.88  105.51  252.23   56.23  227.08  412.54  615.53    3.22   \n",
      "21     0.64   54.36   56.12  123.90   48.81  668.50  676.24  888.58  210.41   \n",
      "22     9.78   14.91   20.14   23.04   55.69   95.36   95.68  101.60   68.72   \n",
      "23   236.47  248.14  298.92  371.57   16.29   66.12  179.11  367.37   96.99   \n",
      "24     1.09   90.71  246.87  570.95  203.32  325.75  341.08  479.43   65.21   \n",
      "25   132.65  197.88  474.13  527.01   26.73  151.38  174.22  338.59    1.26   \n",
      "26   151.94  244.72  269.62  344.08    1.26    3.40   20.28   30.96   63.97   \n",
      "27    52.79   82.90   88.56  109.06    5.93  108.72  166.38  245.49   13.38   \n",
      "28    69.22  152.84  237.07  241.89   23.08  129.45  243.97  395.86    0.02   \n",
      "29     8.57   32.44   79.48   86.04    9.67  460.34  492.92  615.22  244.31   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "570   56.48  117.12  244.83  254.89    3.34   11.06   12.62   17.96  289.73   \n",
      "571   19.50   89.65  124.48  150.86  233.23  244.07  244.43  249.07   95.62   \n",
      "572    6.89   10.81   49.88   54.78  225.62  255.16  275.51  395.62   44.03   \n",
      "573  534.55  540.28  703.92  814.51  113.47  143.53  493.51  668.71   15.36   \n",
      "574   29.50  254.66  463.73  597.24  425.32  538.09  708.62  748.61  235.43   \n",
      "575   36.63  189.27  340.27  493.61   47.52   52.75   55.21  112.68   50.09   \n",
      "576  393.03  434.70  530.75  539.67    9.74   24.83  116.59  153.94   48.87   \n",
      "577  181.62  222.63  288.69  295.50  124.67  356.71  381.87  525.62   42.62   \n",
      "578   78.15  114.03  201.03  260.72   79.45  207.64  243.08  346.94    4.20   \n",
      "579    1.26   15.71   58.60  109.60  875.26  921.20  930.61  961.23   27.31   \n",
      "580   21.24   23.68   25.45   26.32   87.28  100.89  110.18  168.23  344.65   \n",
      "581  266.43  437.47  457.42  593.37   55.73   75.45  302.47  387.55   31.77   \n",
      "582  163.49  172.58  499.29  588.29  273.58  383.41  475.17  505.52    3.66   \n",
      "583  145.73  408.27  590.03  619.41  318.72  359.93  411.04  785.83   16.82   \n",
      "584  319.57  320.30  356.22  360.48    2.89   21.86   25.64   60.07   71.49   \n",
      "585   60.67  125.44  169.15  235.38   66.29  171.17  184.92  254.49  189.13   \n",
      "586    7.64   45.39  153.51  159.78   57.42  118.64  143.38  205.23   55.84   \n",
      "587   11.25   74.70   93.52  116.57  610.53  646.07  646.48  703.29  114.06   \n",
      "588  438.14  552.82  573.69  652.63  376.87  446.71  494.08  803.78    5.50   \n",
      "589   16.83  124.73  340.87  489.16   14.65   21.89  104.50  126.44   56.48   \n",
      "590   96.71  358.70  407.69  627.41  141.90  221.78  258.35  276.95    0.47   \n",
      "591  329.28  337.47  530.68  580.28  198.45  228.60  285.76  511.33   12.86   \n",
      "592  123.86  200.21  253.91  292.48   16.84  296.44  306.84  762.80  383.08   \n",
      "593  121.87  181.60  310.41  338.74    0.98    2.27    2.48    3.41   18.32   \n",
      "594   18.84   77.36  112.34  148.60   28.45   46.28   58.19   83.58  279.63   \n",
      "595   34.79   46.14   76.18   77.16    2.62  362.45  381.59  386.28   62.20   \n",
      "596   73.00  268.16  463.22  541.51  241.82  295.17  331.13  575.25   99.69   \n",
      "597  250.48  391.31  621.12  651.81   64.26  112.56  658.79  751.82    6.13   \n",
      "598   27.04  147.63  322.44  342.39   30.28   53.21   58.19   62.89    6.85   \n",
      "599  109.31  256.64  389.21  448.16   94.82  111.79  153.55  256.87   78.45   \n",
      "\n",
      "        9     ...       502     503     504     505     506     507     508  \\\n",
      "0    125.13   ...    266.13  280.16   75.74  129.71  367.17  387.05   25.26   \n",
      "1    133.44   ...    289.27  407.39  151.72  279.70  382.50  690.74   19.21   \n",
      "2    141.69   ...    449.22  529.50    4.69    5.81   13.64   22.86  103.76   \n",
      "3    207.88   ...    632.46  636.24   67.78   86.45  167.27  266.47   31.21   \n",
      "4    166.95   ...     74.88   88.90   83.19  190.15  329.11  506.73    7.72   \n",
      "5     82.43   ...    255.45  262.16  216.32  316.88  448.42  629.01  110.10   \n",
      "6     22.38   ...    495.08  512.51   23.41   44.01   56.09  127.96   40.99   \n",
      "7     86.01   ...    653.00  689.92  187.50  257.80  340.29  378.15    4.32   \n",
      "8    577.14   ...    410.74  792.20  212.21  325.24  341.95  347.21  309.19   \n",
      "9    484.52   ...     62.76   93.07   87.79  114.84  519.45  962.47  131.88   \n",
      "10    68.67   ...    231.19  241.78  143.77  168.58  169.61  191.42    9.61   \n",
      "11   191.74   ...    371.77  473.83  142.06  190.19  219.62  325.94  294.57   \n",
      "12   277.72   ...    216.81  483.04   36.37   52.48  531.16  691.98   31.45   \n",
      "13   180.23   ...    339.40  575.59   37.71   58.96   60.11   61.44   77.27   \n",
      "14   226.16   ...     53.34   64.55   13.55  131.57  150.25  268.86  458.43   \n",
      "15    45.53   ...    166.61  207.36    7.68   63.62  401.53  501.79   79.79   \n",
      "16    41.14   ...    293.37  435.59  198.64  607.32  720.42  757.77    7.39   \n",
      "17    27.71   ...    314.58  456.36   61.08   92.39  158.76  170.69  126.20   \n",
      "18   198.17   ...    646.42  879.72   72.96  187.73  431.35  455.76   59.76   \n",
      "19   515.99   ...     83.59   98.71  458.02  631.64  715.05  741.75  120.13   \n",
      "20   222.60   ...    259.90  267.60    8.15   16.61   18.22   31.45  162.06   \n",
      "21   268.57   ...    417.35  463.29    9.84   50.58   64.38  280.76  214.61   \n",
      "22   247.79   ...    685.84  693.74   43.04  326.28  442.67  524.93   68.92   \n",
      "23   438.88   ...    146.88  659.41   99.27  176.46  296.29  500.07    0.26   \n",
      "24   208.22   ...     35.84   70.80   22.56   37.88  123.34  134.73   30.55   \n",
      "25    29.86   ...    161.04  191.98   83.48  212.11  220.22  400.31   48.50   \n",
      "26    76.90   ...    294.01  360.45   77.24  105.55  167.43  442.64    4.13   \n",
      "27    20.77   ...    634.07  684.22  274.43  309.55  685.10  782.97   21.52   \n",
      "28     0.10   ...    440.64  836.19    0.21   74.42   82.84  115.50   57.79   \n",
      "29   299.78   ...     46.26   88.76   52.19  194.51  367.30  470.61   11.84   \n",
      "..      ...   ...       ...     ...     ...     ...     ...     ...     ...   \n",
      "570  304.71   ...     97.95  234.91    0.18    2.26    2.70    2.85   42.96   \n",
      "571  187.83   ...    256.03  405.78   27.63  105.74  128.91  169.52    9.63   \n",
      "572  327.22   ...    488.32  603.71   13.89   26.64   78.12  160.76  186.87   \n",
      "573  181.30   ...    828.72  929.68  151.66  533.68  564.48  814.35   38.97   \n",
      "574  276.91   ...    139.53  143.30   25.80   26.27   37.44   76.19   96.46   \n",
      "575  151.90   ...    307.18  319.71  104.02  134.63  321.62  383.07  191.38   \n",
      "576   81.89   ...    457.10  477.40   17.63  205.28  272.48  417.36   14.70   \n",
      "577   60.15   ...    587.86  616.38  256.32  329.58  675.89  945.55  393.72   \n",
      "578   66.45   ...    726.61  736.63   88.84   90.57  133.68  210.27  282.93   \n",
      "579   34.55   ...    106.17  138.44   40.78   87.94  217.81  287.81   41.54   \n",
      "580  805.14   ...    221.66  235.93  170.02  369.83  599.07  600.91   59.53   \n",
      "581  136.67   ...    323.86  346.98   22.39   28.60   32.58   55.03   94.79   \n",
      "582  203.43   ...    406.91  439.30   46.01  175.83  189.27  321.85   10.10   \n",
      "583  333.43   ...    520.63  658.83  101.29  329.24  369.01  508.01  261.48   \n",
      "584  257.51   ...     87.99  125.56  108.15  452.78  571.80  729.68  127.23   \n",
      "585  345.57   ...    153.65  234.82   33.32   81.41  119.65  125.27   53.96   \n",
      "586   72.24   ...    218.05  408.73   50.13  136.05  327.11  397.20  122.79   \n",
      "587  201.48   ...    328.23  609.71  409.16  556.44  557.61  651.28   49.05   \n",
      "588   78.42   ...    591.50  837.77    2.71    4.55    5.33    8.95    7.75   \n",
      "589   77.87   ...    113.13  133.09   16.53   19.50  244.13  268.47   13.04   \n",
      "590   14.90   ...     55.22   72.87  347.63  372.80  400.78  502.35  294.35   \n",
      "591  181.80   ...     90.63  101.10  208.23  251.36  300.30  783.62  126.88   \n",
      "592  483.90   ...    120.47  275.75    0.50  103.66  120.07  121.81   15.94   \n",
      "593   95.55   ...    216.64  524.61    3.73  170.96  262.67  268.18    8.56   \n",
      "594  398.37   ...    101.13  131.57    9.79   34.49  205.46  239.11  187.41   \n",
      "595  135.32   ...    312.29  328.42   34.61   88.29  578.86  911.63    4.12   \n",
      "596  105.32   ...    467.54  498.89   31.63   45.78  142.14  170.81  318.23   \n",
      "597  132.19   ...    606.80  650.64   90.11  128.17  208.94  403.17   73.63   \n",
      "598  215.07   ...    726.91  783.67   71.63  171.64  295.13  712.28   39.71   \n",
      "599   86.14   ...     96.71  104.90   18.46   39.16   55.52   68.87  186.64   \n",
      "\n",
      "        509     510     511  \n",
      "0    125.77  149.49  284.87  \n",
      "1    353.76  492.37  534.29  \n",
      "2    205.98  372.56  613.87  \n",
      "3     90.63  116.32  273.30  \n",
      "4     14.52   23.53   28.09  \n",
      "5    112.53  113.44  719.24  \n",
      "6    230.59  247.00  278.04  \n",
      "7     19.13   19.42   84.09  \n",
      "8    582.48  647.02  767.30  \n",
      "9    205.99  368.06  426.86  \n",
      "10    30.86  109.56  118.86  \n",
      "11   528.14  560.09  689.74  \n",
      "12   150.25  395.54  445.43  \n",
      "13    85.97  133.77  164.80  \n",
      "14   597.68  770.29  831.23  \n",
      "15   168.03  271.39  349.72  \n",
      "16   134.20  164.29  172.84  \n",
      "17   342.05  491.13  515.44  \n",
      "18   289.41  327.83  586.51  \n",
      "19   166.16  174.25  265.82  \n",
      "20   210.96  367.47  370.09  \n",
      "21   449.73  510.83  533.91  \n",
      "22    76.48   91.56  144.76  \n",
      "23     0.95    2.56    3.13  \n",
      "24   125.31  210.22  466.59  \n",
      "25   108.64  169.56  310.06  \n",
      "26    19.24   44.92   46.70  \n",
      "27   212.66  384.55  666.91  \n",
      "28   184.41  293.40  407.18  \n",
      "29    74.35   91.47   96.42  \n",
      "..      ...     ...     ...  \n",
      "570   47.52   52.06   67.64  \n",
      "571  195.01  208.15  671.32  \n",
      "572  346.23  366.39  389.03  \n",
      "573   60.25   93.89  100.46  \n",
      "574  206.88  590.60  690.32  \n",
      "575  325.85  331.91  355.83  \n",
      "576   58.25  105.65  154.75  \n",
      "577  427.34  495.38  818.95  \n",
      "578  307.92  488.04  530.28  \n",
      "579   71.32  102.91  113.77  \n",
      "580  385.68  671.01  725.12  \n",
      "581  219.46  245.28  347.55  \n",
      "582   35.20   85.69  151.14  \n",
      "583  616.56  631.25  937.88  \n",
      "584  141.50  167.93  256.09  \n",
      "585  227.42  254.17  272.31  \n",
      "586  237.15  269.18  493.29  \n",
      "587   75.85  440.60  542.56  \n",
      "588   24.74  120.96  258.74  \n",
      "589   18.47   33.31   36.99  \n",
      "590  648.32  662.64  689.59  \n",
      "591  230.43  350.01  379.89  \n",
      "592   40.73   62.34   69.82  \n",
      "593  111.40  588.50  615.37  \n",
      "594  245.56  252.24  322.11  \n",
      "595   10.56   88.15  129.42  \n",
      "596  499.87  500.31  526.42  \n",
      "597  129.67  279.71  400.79  \n",
      "598   92.00  122.80  157.57  \n",
      "599  396.74  422.76  548.26  \n",
      "\n",
      "[600 rows x 512 columns]\n",
      "##### AFTER #####\n",
      "          0         1         2         3         4         5         6    \\\n",
      "0    0.721501  0.265725  0.928713  0.517218  0.095862  0.394373 -0.082502   \n",
      "1   -0.784062 -1.065108  0.660303  1.128594 -0.170681 -0.539045 -0.579815   \n",
      "2    1.844829  0.956976  0.366285  0.259717 -0.547681 -0.564799  1.200907   \n",
      "3    0.492984  0.241269 -0.125481  0.275203 -0.807306 -0.973271 -1.126084   \n",
      "4   -0.815684 -0.717460 -0.709313 -0.819836 -0.593310 -0.571586 -0.523682   \n",
      "5    0.199432 -0.215356 -0.475445 -0.733948 -0.394005  0.801569  0.406407   \n",
      "6   -0.588062 -0.966918 -1.194820 -1.345487  1.200045  1.138694  0.691745   \n",
      "7    0.311765  1.430763  0.969227  1.629857 -0.042656  0.067224  0.535479   \n",
      "8    0.498986  0.282274  0.600104  1.252203 -0.517754 -0.647746 -0.937668   \n",
      "9    2.259135  1.160220  1.127846  1.040105 -0.578463 -0.786088 -0.965380   \n",
      "10   0.264198 -0.322494 -0.094378 -0.060869 -0.596108 -0.864859  0.278939   \n",
      "11   0.719441  0.084791  0.043171  0.129848 -0.279117  1.044900  1.320774   \n",
      "12  -0.496064 -0.917088 -0.730525 -0.758052 -0.869491 -1.153725 -1.335036   \n",
      "13  -0.268980 -0.693862 -0.871276 -0.938323 -0.723822 -0.255168 -0.587557   \n",
      "14  -0.858144 -1.189101 -1.308385 -1.465600  0.319419  0.292748 -0.155867   \n",
      "15   2.071734  1.219060  1.020778  1.323010 -0.476634 -0.414218  0.018575   \n",
      "16  -0.773581 -0.759628  0.155446 -0.049691  1.321540  1.742759  1.067066   \n",
      "17   0.223618  0.445188  0.117368  0.660499 -0.830237 -1.073329 -1.282397   \n",
      "18   1.013979  0.685391  0.880649  0.480554 -0.728097 -1.046357 -0.548325   \n",
      "19   0.254165 -0.253786 -0.615766 -0.615217 -0.635129  0.204348  0.325536   \n",
      "20  -0.775731 -0.695517 -0.934245 -0.595869 -0.444220  0.134452  0.570981   \n",
      "21  -0.892364 -0.888709 -1.170215 -1.117496 -0.501897  2.694913  1.815915   \n",
      "22  -0.810488 -1.130506 -1.342115 -1.527465 -0.448417 -0.629591 -0.924921   \n",
      "23   1.220191  0.299006 -0.010196 -0.110784 -0.754681 -0.799197 -0.531046   \n",
      "24  -0.888333 -0.665913 -0.258874  0.699643  0.699140  0.706788  0.233617   \n",
      "25   0.290176 -0.009047  0.826901  0.521038 -0.673529 -0.304646 -0.554132   \n",
      "26   0.462975  0.278045 -0.150181 -0.222523 -0.871512 -1.163005 -1.280886   \n",
      "27  -0.425206 -0.713782 -1.015227 -1.177817 -0.835211 -0.552096 -0.591145   \n",
      "28  -0.278027 -0.285106 -0.305695 -0.637898 -0.701901 -0.431851 -0.224841   \n",
      "29  -0.821327 -1.023061 -1.058608 -1.271387 -0.806140  1.487479  0.950457   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "570 -0.392152 -0.504041 -0.268620 -0.585057 -0.855344 -1.118573 -1.317049   \n",
      "571 -0.723417 -0.672410 -0.843613 -1.007911  0.931636  0.233003 -0.222669   \n",
      "572 -0.836377 -1.155636 -1.200027 -1.398451  0.872482  0.297331 -0.075940   \n",
      "573  3.890378  2.089590  1.924762  1.689649  0.000718 -0.350180  0.953243   \n",
      "574 -0.633837  0.338969  0.777213  0.806505  2.424790  1.938468  1.968781   \n",
      "575 -0.569967 -0.061819  0.187361  0.385276 -0.511924 -0.876750 -1.115981   \n",
      "576  2.622648  1.442469  1.097412  0.572498 -0.805596 -1.038700 -0.826205   \n",
      "577  0.728847  0.142651 -0.059071 -0.419988  0.087778  0.886372  0.426188   \n",
      "578 -0.198033 -0.522980 -0.477882 -0.561359 -0.263726  0.021690 -0.229043   \n",
      "579 -0.886810 -1.125603 -1.158366 -1.175622  5.922262  4.160701  3.016801   \n",
      "580 -0.707830 -1.076753 -1.316746 -1.514133 -0.202862 -0.597514 -0.856466   \n",
      "581  1.488571  1.459447  0.747066  0.790774 -0.448106 -0.745079  0.051339   \n",
      "582  0.566439 -0.164116  0.947107  0.770125  1.245285  1.041246  0.866659   \n",
      "583  0.407346  1.280475  1.380633  0.896620  1.596167  0.905050  0.563900   \n",
      "584  1.964597  0.741289  0.263565 -0.155862 -0.858842 -1.055928 -1.255582   \n",
      "585 -0.354618 -0.453046 -0.630194 -0.664360 -0.366021 -0.189854 -0.503617   \n",
      "586 -0.829658 -0.943688 -0.704917 -0.971654 -0.434970 -0.494555 -0.699729   \n",
      "587 -0.797320 -0.764042 -0.991530 -1.147291  3.864463  2.564807  1.675417   \n",
      "588  3.026742  2.166450  1.302566  1.031650  2.048178  1.408418  0.955934   \n",
      "589 -0.747334 -0.457398  0.190228  0.367188 -0.767429 -1.055754 -0.883282   \n",
      "590 -0.031773  0.976650  0.509472  0.929138  0.221710  0.103710 -0.156953   \n",
      "591  2.051579  0.846528  1.097078  0.737567  0.661284  0.143269 -0.027550   \n",
      "592  0.211436  0.005234 -0.225239 -0.432264 -0.750406  0.536776  0.071970   \n",
      "593  0.193609 -0.108830  0.044700 -0.244229 -0.873689 -1.169560 -1.364920   \n",
      "594 -0.729329 -0.747738 -0.901614 -1.017097 -0.660159 -0.914280 -1.101912   \n",
      "595 -0.586450 -0.939091 -1.074375 -1.307482 -0.860941  0.919667  0.424866   \n",
      "596 -0.244166  0.421713  0.774776  0.579977  0.998408  0.529409  0.186643   \n",
      "597  1.345692  1.176524  1.529171  1.028317 -0.381801 -0.529822  1.733533   \n",
      "598 -0.655874 -0.317039  0.102175 -0.229393 -0.645934 -0.874082 -1.101912   \n",
      "599  0.081097  0.351105  0.421180  0.200534 -0.144252 -0.534288 -0.651716   \n",
      "\n",
      "          7         8         9      ...          502       503       504  \\\n",
      "0   -0.069345 -0.803603 -0.407241    ...    -0.166940 -0.482342 -0.221075   \n",
      "1   -0.277638 -0.182204 -0.355357    ...    -0.055471  0.030502  0.467502   \n",
      "2    1.480300 -0.640353 -0.303848    ...     0.715035  0.522708 -0.864973   \n",
      "3   -1.309940 -0.105862  0.109415    ...     1.597732  0.952961 -0.293213   \n",
      "4   -0.645277  0.272042 -0.146135    ...    -1.088223 -1.253282 -0.153559   \n",
      "5    0.429839 -0.819310 -0.673842    ...    -0.218388 -0.554898  1.052946   \n",
      "6    0.222837 -0.645017 -1.048769    ...     0.935950  0.454224 -0.695321   \n",
      "7    2.174379 -0.244934 -0.651490    ...     1.696677  1.169336  0.791762   \n",
      "8   -1.057181  0.914954  2.414918    ...     0.529670  1.581611  1.015699   \n",
      "9   -0.875964  0.700396  1.836638    ...    -1.146607 -1.236473 -0.111871   \n",
      "10   0.444567 -0.799510 -0.759754    ...    -0.335252 -0.637046  0.395454   \n",
      "11   1.452659  0.791397  0.008643    ...     0.341945  0.298311  0.379957   \n",
      "12  -1.527110 -0.425414  0.545466    ...    -0.404523  0.335435 -0.577870   \n",
      "13  -0.684175 -0.004294 -0.063220    ...     0.186013  0.708490 -0.565726   \n",
      "14  -0.524707  1.061260  0.223547    ...    -1.191985 -1.351433 -0.784678   \n",
      "15   1.011056 -0.816739 -0.904230    ...    -0.646345 -0.775788 -0.837876   \n",
      "16   1.335318 -0.699561 -0.931639    ...    -0.035721  0.144172  0.892719   \n",
      "17  -1.407066 -0.783804 -1.015490    ...     0.066451  0.227892 -0.353933   \n",
      "18  -0.532576  1.018330  0.048790    ...     1.664980  1.934391 -0.246269   \n",
      "19   0.447553 -0.227514  2.033123    ...    -1.046266 -1.213739  3.243377   \n",
      "20   0.907636 -0.795131  0.201320    ...    -0.196951 -0.532970 -0.833616   \n",
      "21   2.009424  1.177106  0.488337    ...     0.561512  0.255826 -0.818301   \n",
      "22  -1.166129 -0.171638  0.358596    ...     1.854873  1.184734 -0.517422   \n",
      "23  -0.093717  0.097464  1.551681    ...    -0.741387  1.046355 -0.007832   \n",
      "24   0.358458 -0.205050  0.111538    ...    -1.276286 -1.326240 -0.703024   \n",
      "25  -0.209848 -0.813789 -1.002067    ...    -0.673176 -0.837782 -0.150930   \n",
      "26  -1.451169 -0.216853 -0.708369    ...    -0.032638 -0.158706 -0.207481   \n",
      "27  -0.585517 -0.698418 -1.058821    ...     1.605488  1.146361  1.579574   \n",
      "28   0.021243 -0.825592 -1.187876    ...     0.673703  1.758928 -0.905573   \n",
      "29   0.906386  1.499800  0.683199    ...    -1.226091 -1.253846 -0.434499   \n",
      "..        ...       ...       ...    ...          ...       ...       ...   \n",
      "570 -1.503626  1.932152  0.713980    ...    -0.977091 -0.664738 -0.905845   \n",
      "571 -0.571071  0.084423 -0.015769    ...    -0.215594  0.024012 -0.657077   \n",
      "572  0.020275 -0.406662  0.854523    ...     0.903386  0.821837 -0.781597   \n",
      "573  1.122224 -0.679571 -0.056540    ...     2.543149  2.135772  0.466958   \n",
      "574  1.444629  1.415271  0.540409    ...    -0.776794 -1.034004 -0.673661   \n",
      "575 -1.121420 -0.348977 -0.240101    ...     0.030804 -0.322923  0.035215   \n",
      "576 -0.954931 -0.360590 -0.677213    ...     0.752994  0.312701 -0.747703   \n",
      "577  0.544839 -0.420083 -0.812949    ...     1.382887  0.872908  1.415450   \n",
      "578 -0.176154 -0.785803 -0.773614    ...     2.051268  1.357617 -0.102355   \n",
      "579  2.302575 -0.565819 -0.972784    ...    -0.937494 -1.053594 -0.537904   \n",
      "580 -0.897269  2.454935  3.838453    ...    -0.381160 -0.660627  0.633347   \n",
      "581 -0.012289 -0.523364 -0.335190    ...     0.111155 -0.213001 -0.704565   \n",
      "582  0.463734 -0.790943  0.081631    ...     0.511220  0.159126 -0.490506   \n",
      "583  1.594816 -0.665673  0.893296    ...     1.059028  1.044017  0.010475   \n",
      "584 -1.333707 -0.145270  0.419283    ...    -1.025070 -1.105511  0.072644   \n",
      "585 -0.549201  0.974543  0.969093    ...    -0.708775 -0.665101 -0.605511   \n",
      "586 -0.747970 -0.294243 -0.737464    ...    -0.398550  0.035903 -0.453168   \n",
      "587  1.261758  0.259953  0.069456    ...     0.132206  0.846022  2.800578   \n",
      "588  1.667246 -0.773428 -0.698879    ...     1.400421  1.765297 -0.882917   \n",
      "589 -1.065897 -0.288150 -0.702313    ...    -0.903967 -1.075159 -0.757672   \n",
      "590 -0.458572 -0.821309 -1.095471    ...    -1.182929 -1.317896  2.242956   \n",
      "591  0.487178 -0.703368 -0.053418    ...    -1.012353 -1.204106  0.979629   \n",
      "592  1.501887  2.820749  1.832767    ...    -0.868609 -0.500119 -0.902945   \n",
      "593 -1.562337 -0.651395 -0.591926    ...    -0.405342  0.502997 -0.873673   \n",
      "594 -1.238842  1.836010  1.298754    ...    -0.961773 -1.081286 -0.818754   \n",
      "595 -0.017413 -0.233702 -0.343619    ...     0.055420 -0.287814 -0.593820   \n",
      "596  0.745102  0.123165 -0.530926    ...     0.803285  0.399324 -0.620826   \n",
      "597  1.457582 -0.767431 -0.363162    ...     1.474124  1.011005 -0.090845   \n",
      "598 -1.322328 -0.760577  0.154306    ...     2.052714  1.547228 -0.258322   \n",
      "599 -0.539597 -0.079018 -0.650678    ...    -0.983065 -1.188788 -0.740181   \n",
      "\n",
      "          505       506       507       508       509       510       511  \n",
      "0   -0.422451  0.304286 -0.045167 -0.678121 -0.495537 -0.733540 -0.449244  \n",
      "1    0.500585  0.378074  1.175756 -0.734706  0.887821  0.884605  0.552503  \n",
      "2   -1.184930 -1.397363 -1.509316  0.056081 -0.008853  0.319189  0.872121  \n",
      "3   -0.688673 -0.657895 -0.529933 -0.622471 -0.708754 -0.890078 -0.495713  \n",
      "4   -0.050504  0.121091  0.435982 -0.842170 -1.170561 -1.327979 -1.480551  \n",
      "5    0.729390  0.695367  0.927583  0.115378 -0.575873 -0.903670  1.295319  \n",
      "6   -0.949848 -1.193038 -1.086784 -0.531000  0.140472 -0.273363 -0.476675  \n",
      "7    0.365813  0.174904 -0.080947 -0.873970 -1.142589 -1.347376 -1.255638  \n",
      "8    0.780838  0.182894 -0.205335  1.977444  2.275609  1.614441  1.488343  \n",
      "9   -0.513961  1.037256  2.268190  0.319084 -0.008792  0.297952  0.121031  \n",
      "10  -0.183246 -0.646632 -0.831656 -0.824493 -1.071416 -0.921980 -1.115991  \n",
      "11  -0.050258 -0.405918 -0.290847  1.840705  1.945894  1.204194  1.176838  \n",
      "12  -0.897723  1.093620  1.180741 -0.620226 -0.347002  0.427638  0.195614  \n",
      "13  -0.857846 -1.173689 -1.354214 -0.191677 -0.737029 -0.807727 -0.931482  \n",
      "14  -0.411005 -0.739817 -0.520325  3.373269  2.367837  2.196185  1.745105  \n",
      "15  -0.829168  0.469671  0.416122 -0.168108 -0.239119 -0.158260 -0.188787  \n",
      "16   2.516754  2.004587  1.445236 -0.845257 -0.444387 -0.663694 -0.899191  \n",
      "17  -0.652118 -0.698856 -0.914997  0.265960  0.816769  0.878753  0.476796  \n",
      "18  -0.065397  0.613204  0.231068 -0.355446  0.497369  0.108096  0.762235  \n",
      "19   2.666419  1.978739  1.380831  0.209188 -0.250466 -0.616690 -0.525755  \n",
      "20  -1.118467 -1.375318 -1.474782  0.601354  0.021364  0.295168 -0.106974  \n",
      "21  -0.909416 -1.153136 -0.472483  1.092848  1.470132  0.971723  0.550977  \n",
      "22   0.787238  0.667690  0.509151 -0.269774 -0.794611 -1.006927 -1.011969  \n",
      "23  -0.134752 -0.036882  0.409207 -0.911943 -1.252899 -1.426943 -1.580798  \n",
      "24  -0.987572 -0.869343 -1.059566 -0.628644 -0.498328 -0.446938  0.280599  \n",
      "25   0.084637 -0.403030  0.008143 -0.460759 -0.599476 -0.638824 -0.348073  \n",
      "26  -0.571131 -0.657125  0.178322 -0.875747 -1.141922 -1.227034 -1.405808  \n",
      "27   0.684282  1.834581  1.546547 -0.713100  0.031679  0.375773  1.085146  \n",
      "28  -0.762705 -1.064282 -1.136877 -0.373871 -0.139732 -0.054389  0.041990  \n",
      "29  -0.023673  0.304911  0.290769 -0.803636 -0.807535 -1.007352 -1.206117  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "570 -1.206777 -1.450021 -1.589763 -0.512574 -0.970329 -1.193339 -1.321706  \n",
      "571 -0.569962 -0.842533 -0.919701 -0.824306 -0.075415 -0.456707  1.102857  \n",
      "572 -1.056742 -1.087001 -0.954918  0.833399  0.842132  0.290071 -0.030906  \n",
      "573  2.063575  1.253999  1.672704 -0.549892 -0.893088 -0.995931 -1.189891  \n",
      "574 -1.059019 -1.282807 -1.294914 -0.012195 -0.003392  1.348179  1.179167  \n",
      "575 -0.392174  0.085039 -0.061167  0.875581  0.718474  0.127350 -0.164247  \n",
      "576  0.042606 -0.151487  0.076689 -0.776887 -0.905224 -0.940433 -0.971846  \n",
      "577  0.807546  1.790250  2.200166  2.768044  1.334277  0.898810  1.695785  \n",
      "578 -0.663318 -0.819574 -0.755874  1.731838  0.609681  0.864170  0.536398  \n",
      "579 -0.679503 -0.414630 -0.444140 -0.525856 -0.825920 -0.953363 -1.136434  \n",
      "580  1.055244  1.420492  0.814613 -0.357597  1.081500  1.727656  1.318935  \n",
      "581 -1.044681 -1.306199 -1.379984 -0.027814  0.072939 -0.281480 -0.197502  \n",
      "582 -0.138629 -0.552002 -0.307290 -0.819910 -1.045082 -1.034629 -0.986345  \n",
      "583  0.805454  0.313142  0.441128  1.531218  2.482394  1.540018  2.173444  \n",
      "584  1.565717  1.289233  1.332306  0.275593 -0.400093 -0.646516 -0.564833  \n",
      "585 -0.719689 -0.887105 -1.097598 -0.409693  0.121237 -0.239526 -0.499689  \n",
      "586 -0.383435  0.111464 -0.004361  0.234066  0.180275 -0.168690  0.387834  \n",
      "587  2.203639  1.220932  1.017115 -0.455615 -0.798433  0.640288  0.585718  \n",
      "588 -1.192684 -1.437362 -1.565239 -0.841890 -1.108550 -0.868181 -0.554190  \n",
      "589 -1.100682 -0.287944 -0.521893 -0.792413 -1.146594 -1.281825 -1.444806  \n",
      "590  1.073521  0.466061  0.418373  1.838648  2.675102  1.688156  1.176235  \n",
      "591  0.326181 -0.017580  1.549161  0.272320  0.139501  0.212769 -0.067615  \n",
      "592 -0.582762 -0.885083 -1.111509 -0.765289 -1.011528 -1.144824 -1.312951  \n",
      "593 -0.168599 -0.198705 -0.523059 -0.834314 -0.582729  1.338269  0.878145  \n",
      "594 -1.008434 -0.474075 -0.639928  0.838450  0.231304 -0.248634 -0.299677  \n",
      "595 -0.677349  1.323215  2.063798 -0.875841 -1.194589 -1.023020 -1.073579  \n",
      "596 -0.938955 -0.778853 -0.914514  2.061994  1.774363  0.922076  0.520895  \n",
      "597 -0.431928 -0.457324  0.019641 -0.225721 -0.471873 -0.118996  0.016326  \n",
      "598 -0.164415 -0.042465  1.262353 -0.542971 -0.700441 -0.859497 -0.960520  \n",
      "599 -0.979695 -1.195782 -1.324343  0.831248  1.148608  0.556096  0.608611  \n",
      "\n",
      "[600 rows x 512 columns]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"Training classifier \" + str(i) + \"...\")\n",
    "# Data is loaded.\n",
    "TRAINING_FILE = baseDir + 'training/' + str(i) + '.csv' # Training file for current classifier\n",
    "TEST_FILE = baseDir + 'test/' + str(i) + '.csv' # Test file for current classifier\n",
    "training_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "test_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "# print(\"############# TRAINING SET #############\")\n",
    "# print(training_set)\n",
    "\n",
    "# print(\"############# SCALED TRAINING SET #############\")\n",
    "# print(pd.DataFrame(training_set))\n",
    "# apply same transformation to test data\n",
    "# test_set = scaler.transform(test_set)      \n",
    "\n",
    "\n",
    "\n",
    "# Create dataframe for data and separate target.\n",
    "df_training = pd.DataFrame(training_set)\n",
    "df_training_input = df_training.iloc[:, :-1]\n",
    "print(\"##### BEFORE #####\")\n",
    "print(df_training_input.iloc[:,:])\n",
    "df_training_output = df_training.iloc[:, -1]\n",
    "# Scale data because http://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use\n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(df_training_input)\n",
    "# Reconvert input training data to dataframe after scaling (which converts it to an array of arrays).\n",
    "df_training_input = pd.DataFrame(scaler.transform(df_training_input))\n",
    "print(\"##### AFTER #####\")\n",
    "print(df_training_input)\n",
    "\n",
    "# print(\"#############\")\n",
    "# print(df_training)\n",
    "# y_training = df_training.iloc[:, -1]\n",
    "# Validation/testing data is loaded.\n",
    "df_test = pd.DataFrame(test_set)\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
