{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "import parser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import generar_jobs\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the problem parameters are established (should make this dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO receive as parameters\n",
    "task_amount = 128\n",
    "machine_amount = 4\n",
    "task_heterogeneity = 0\n",
    "machine_heterogeneity = 0\n",
    "consistency_type = 0\n",
    "accuracy_scores = []\n",
    "classifiers = []\n",
    "# Classifier configuration.\n",
    "USING_ENTIRE_ETC = True\n",
    "CLASSIFIER_STRING_ANN = 'ann'\n",
    "CLASSIFIER_STRING_SVM = 'svm'\n",
    "classifier_types = [CLASSIFIER_STRING_ANN, CLASSIFIER_STRING_SVM]\n",
    "current_classifier_index = 0 # Only modify this.\n",
    "current_classifier_str = classifier_types[current_classifier_index]\n",
    "# Base path for classifier persistence.\n",
    "model_base_path = './models/' + current_classifier_str + '/' + str(task_amount) + 'x' + str(machine_amount) \\\n",
    "    + '-' + str(task_heterogeneity) + str(machine_heterogeneity) \\\n",
    "    + str(consistency_type) + '/'\n",
    "baseDir = './data-processed/' + str(task_amount) + 'x' \\\n",
    "    + str(machine_amount) + '-' + str(task_heterogeneity) \\\n",
    "    + str(machine_heterogeneity) + str(consistency_type) + '/'\n",
    "model_file_prefix = 'clf-' + current_classifier_str\n",
    "model_file_extension = '.pkl'\n",
    "\n",
    "if current_classifier_str == CLASSIFIER_STRING_ANN:\n",
    "    if USING_ENTIRE_ETC:\n",
    "        dimension = task_amount * machine_amount\n",
    "        # Reference: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "        ns = 600  # Amount of training examples.\n",
    "        ni = dimension\n",
    "        no = 1  # Amount of output neurons.\n",
    "        alpha = 2\n",
    "        hidden_layer_amount = 2 #int(math.ceil(ns / (alpha * (ni + no)))) # Con 2 hardcodeado parece aprender mejor\n",
    "        # Each hidden layer has an intermediate amount of neurons (between the neuron amount\n",
    "        # present in the output layer and the input layer).\n",
    "        # A tuple is generated to set up the MLPClassifier.\n",
    "        hidden_layer_neuron_amount = tuple([int(math.ceil((task_amount - no) / 2))]\n",
    "                                           * hidden_layer_amount)  \n",
    "    else:\n",
    "        dimension = machine_amount\n",
    "        # Reference: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "        ns = 600  # Amount of training examples.\n",
    "        ni = dimension\n",
    "        no = 1  # Amount of output neurons.\n",
    "        alpha = 2\n",
    "        hidden_layer_amount = 2 #int(math.ceil(ns / (alpha * (ni + no)))) # Con 2 hardcodeado parece aprender mejor\n",
    "        # Each hidden layer has an intermediate amount of neurons (between the neuron amount\n",
    "        # present in the output layer and the input layer).\n",
    "        # A tuple is generated to set up the MLPClassifier.\n",
    "        hidden_layer_neuron_amount = tuple([int(math.ceil((ni - no) / 2))]\n",
    "                                           * hidden_layer_amount) \n",
    "elif current_classifier_str == CLASSIFIER_STRING_SVM:\n",
    "    # No mandatory config for SVC method.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, classifiers are loaded (or generated if they don't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO maybe specify classifier configuration along with this (so as to not specify something that might already exist)\n",
    "for i in range(0, task_amount):\n",
    "    try:\n",
    "        classifier = joblib.load(model_base_path + model_file_prefix + str(i) \\\n",
    "                                 + model_file_extension)\n",
    "    except Exception:\n",
    "        print('The classifier for output ' + str(i) + ' didn\\'t exist.')\n",
    "        if current_classifier_str == CLASSIFIER_STRING_ANN:\n",
    "            classifier = MLPClassifier(solver='lbfgs', alpha=1e-2, \n",
    "                hidden_layer_sizes=hidden_layer_neuron_amount, random_state=1)\n",
    "        elif current_classifier_str == CLASSIFIER_STRING_SVM:\n",
    "            classifier = svm.SVC()\n",
    "    finally:\n",
    "        # Append classifier to classifier list (in memory).\n",
    "        classifiers.append(classifier)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, each classifier is trained, and the following is done for each one (after training it):\n",
    "* Its accuracy is determined using the training set\n",
    "* Each training set instance is iterated over, and the time each machine uses in execution is stored (for calculating the makespan afterwards, in another section) in an array\n",
    "    * Each entry of the array will be an array of machine_amount elements, in which each element corresponds to the time each machine uses up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No threading version.\n",
    "start = time.time()\n",
    "# Each index corresponds to an instance.\n",
    "makespan_instance_machines_heuristic = []\n",
    "makespan_instance_machines_prediction = []\n",
    "SCALE_DATA = True\n",
    "USE_PARAMETER_SELECTION = False\n",
    "# Within each index, there'll be an array of machine_amount elements, in which each element\n",
    "# is the time during which each machine is running\n",
    "# Something along the lines of [[10,20,9,40], [99,88,22,11], ..., [10,9,21,35]]\n",
    "for i in range(0, task_amount): # For each task/classifier\n",
    "    print(\"Training classifier \" + str(i) + \"...\")\n",
    "    # Data is loaded.\n",
    "    TRAINING_FILE = baseDir + 'training/' + str(i) + '.csv' # Training file for current classifier\n",
    "    TEST_FILE = baseDir + 'test/' + str(i) + '.csv' # Test file for current classifier\n",
    "    training_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "    test_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "    \n",
    "    # Create dataframe for data and separate target.\n",
    "    df_training = pd.DataFrame(training_set)\n",
    "    df_training_input = df_training.iloc[:, :-1] # Leave rows alone, slice everything except last column.\n",
    "    # If not using entire ETC,use only the column relevant to the task/classifier.\n",
    "    if not USING_ENTIRE_ETC:\n",
    "        df_training_input = df_training_input.iloc[:, i * machine_amount : i * machine_amount + machine_amount]\n",
    "    df_training_output = df_training.iloc[:, -1]\n",
    "    \n",
    "    # Validation/testing data is loaded.\n",
    "    df_test = pd.DataFrame(test_set)\n",
    "    df_test_input = df_test.iloc[:, :-1]\n",
    "    # If not using entire ETC,use only the column relevant to the task/classifier.\n",
    "    if not USING_ENTIRE_ETC:\n",
    "        df_test_input = df_test_input.iloc[:, i * machine_amount : i * machine_amount + machine_amount]    \n",
    "    df_test_output = df_test.iloc[:, -1]\n",
    "    if SCALE_DATA:\n",
    "        # Scale data because http://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use\n",
    "        scaler = StandardScaler()  \n",
    "        # Fit only on training data.\n",
    "        scaler.fit(df_training_input)\n",
    "        # Reconvert input training data to dataframe after scaling (which converts it to an array of arrays).\n",
    "        df_training_input = pd.DataFrame(scaler.transform(df_training_input))\n",
    "        # Re-init scaler just in case.\n",
    "        scaler = StandardScaler()  \n",
    "        scaler.fit(df_test_input)\n",
    "        # Scale test data.\n",
    "        df_test_input = pd.DataFrame(scaler.transform(df_test_input))        \n",
    "    if current_classifier_str == CLASSIFIER_STRING_SVM:\n",
    "        if USE_PARAMETER_SELECTION:\n",
    "            # Grid of parameters, including all posible parameters for each configuration of\n",
    "            # an SVM classifier.\n",
    "            param_grid = [\n",
    "              {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    "             ]\n",
    "            # Run grid search with all the possible classifier configurations.\n",
    "            classifiers[i] = GridSearchCV(classifiers[i], param_grid=param_grid)\n",
    "            # This generates multiple estimators.\n",
    "            # Now the prediction will use the best estimator of all.\n",
    "            # Should use grid_search as new classifier, persist it, and use it for prediction\n",
    "            # as a normal classifier (according to documentation it uses the best estimator)\n",
    "            # However, it fits every possible estimator with the data, so that's something of note.            \n",
    "    # Classifier is trained using the data.\n",
    "    classifiers[i].fit(df_training_input, df_training_output)\n",
    "    # Classifier directory is generated if it doesn't exist.\n",
    "    generar_jobs.generate_dir(model_base_path)\n",
    "    # Classifier is persisted.\n",
    "    joblib.dump(classifiers[i], model_base_path + model_file_prefix + str(i) \\\n",
    "                + model_file_extension)\n",
    "    # Classifier accuracy is determined using test data.\n",
    "    results = []\n",
    "    # Go through every test instance manually to calculate makespan for each\n",
    "    # problem-classifier/task pair\n",
    "    current_task_index = i * machine_amount # Column index within etc matrix\n",
    "    print(\"    Doing makespan stuff...\")\n",
    "    test_instance_amount = len(df_test)\n",
    "    for j in range(0, test_instance_amount): # For every validation instance\n",
    "        if USING_ENTIRE_ETC:\n",
    "            # df_test.iloc[j] is an ETC matrix + the corresponding classification for one task\n",
    "            etc_matrix_scaled = df_test_input.iloc[j] # Scaled data for classification (since classifiers were\n",
    "            # trained using scaled data)\n",
    "            # Non-scaled data is used to calculate real makespan, using the original units of the problem.\n",
    "            etc_matrix = df_test.iloc[j][:-1] # Get j problem instance, ignoring last column (the output/classification).\n",
    "            classification_heuristic = float(df_test_output[j])\n",
    "            # Every test example is classified, and its classification is appended\n",
    "            # to a results array.\n",
    "            # Make prediction for current problem instance or etc matrix (using scaled data).\n",
    "            prediction_pandas = float(classifiers[i].predict(etc_matrix_scaled.values.reshape(1, -1)))\n",
    "            results.append(prediction_pandas)\n",
    "            prediction = float(prediction_pandas) # To work in floats.\n",
    "\n",
    "            # Get subrow from original input data, to get the task/machine times right.\n",
    "            sub_row_for_current_task = etc_matrix[current_task_index:current_task_index + machine_amount]\n",
    "            # Makespan value for prediction\n",
    "            current_makespan_prediction = sub_row_for_current_task[current_task_index + prediction]\n",
    "            # Makespan value for heuristic\n",
    "            current_makespan_heuristic = sub_row_for_current_task[current_task_index + classification_heuristic]\n",
    "            if len(makespan_instance_machines_prediction) <= j: # If there's no entry for this problem instance.\n",
    "                # Init entry for problem instance, with each machine's makespan starting at 0.0.\n",
    "                makespan_instance_machines_prediction.append([0.0] * machine_amount)\n",
    "                makespan_instance_machines_heuristic.append([0.0] * machine_amount)\n",
    "            makespan_instance_machines_prediction[j][int(prediction)] += current_makespan_prediction\n",
    "            makespan_instance_machines_heuristic[j][int(classification_heuristic)] += current_makespan_heuristic\n",
    "        else:\n",
    "            # df_test.iloc[j] is an ETC matrix + the corresponding classification for one task\n",
    "            sub_row_for_current_task_scaled = df_test_input.iloc[j] # Scaled data for classification (since classifiers were\n",
    "            # trained using scaled data)\n",
    "            # Non-scaled data is used to calculate real makespan, using the original units of the problem.\n",
    "#             etc_matrix = df_test.iloc[j][:-1] # Get j problem instance, ignoring last column (the output/classification).\n",
    "#             print(\"A: \")\n",
    "#             print(etc_matrix_scaled)\n",
    "#             print(\"B: \")\n",
    "            sub_row_for_current_task = df_test.iloc[:, :-1].iloc[j, i * machine_amount : i * machine_amount + machine_amount]                \n",
    "#             print(etc_matrix)\n",
    "            classification_heuristic = float(df_test_output[j])\n",
    "            # Every test example is classified, and its classification is appended\n",
    "            # to a results array.\n",
    "            # Make prediction for current problem instance or etc matrix (using scaled data).\n",
    "            prediction_pandas = float(classifiers[i].predict(sub_row_for_current_task_scaled.values.reshape(1, -1)))\n",
    "            results.append(prediction_pandas)\n",
    "            prediction = float(prediction_pandas) # To work in floats.\n",
    "\n",
    "            # Makespan value for prediction\n",
    "            current_makespan_prediction = sub_row_for_current_task[current_task_index + prediction]\n",
    "            # Makespan value for heuristic\n",
    "            current_makespan_heuristic = sub_row_for_current_task[current_task_index + classification_heuristic]\n",
    "            if len(makespan_instance_machines_prediction) <= j: # If there's no entry for this problem instance.\n",
    "                # Init entry for problem instance, with each machine's makespan starting at 0.0.\n",
    "                makespan_instance_machines_prediction.append([0.0] * machine_amount)\n",
    "                makespan_instance_machines_heuristic.append([0.0] * machine_amount)\n",
    "            makespan_instance_machines_prediction[j][int(prediction)] += current_makespan_prediction\n",
    "            makespan_instance_machines_heuristic[j][int(classification_heuristic)] += current_makespan_heuristic            \n",
    "    print(\"    Done with makespan stuff...\")\n",
    "    # Actual classification results are compared to expected values.\n",
    "    accuracy = accuracy_score(df_test_output, results)\n",
    "    print(\"    Classifier accuracy: \" + str(accuracy))\n",
    "    # Calculated accuracy is added to accuracies list.\n",
    "    accuracy_scores.append(accuracy)\n",
    "end = time.time()\n",
    "print('The execution took ' + str(end - start) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section takes the makespan data (which determines how much time each machine takes for each problem instance) and determines an average makespan for all of the problem instances (how much time the slowest machine takes in completing the tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array that holds makespan values for the prediction.\n",
    "makespan_prediction = []\n",
    "for i in range(0, len(makespan_instance_machines_prediction)):\n",
    "    makespan_prediction.append(np.max(makespan_instance_machines_prediction[i]))\n",
    "# Array that holds makespan values for the heuristic\n",
    "makespan_heuristic = []\n",
    "for i in range(0, len(makespan_instance_machines_heuristic)):\n",
    "    makespan_heuristic.append(np.max(makespan_instance_machines_heuristic[i]))\n",
    "# Array that holds the difference between heuristic and prediction makespan.\n",
    "makespan_diff = []\n",
    "for i in range(0, len(makespan_prediction)):\n",
    "    makespan_diff.append(makespan_prediction[i] - makespan_heuristic[i])\n",
    "# Calculate average difference between methods.\n",
    "avg_difference_between_methods = np.mean(makespan_diff)\n",
    "print('Average difference between techniques: ' + str(avg_difference_between_methods))\n",
    "if avg_difference_between_methods > 0:\n",
    "    print('The heuristic works better on average')\n",
    "elif avg_difference_between_methods < 0:\n",
    "    print('Savant works better on average')\n",
    "else:\n",
    "    print('Both techniques work equivalently on average')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section has multithreading code, needs to be reviewed and updated to match the non-multithreading version of the code (besides it isn't certain that this actually works on a cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO update this to include makespan calculation\n",
    "\n",
    "# # Multithreading version\n",
    "# import os\n",
    "\n",
    "# def train_and_persist_classifier(classifier_index):\n",
    "#     # Data is loaded.\n",
    "#     TRAINING_FILE = baseDir + 'training/' + str(classifier_index) + '.csv'\n",
    "#     TEST_FILE = baseDir + 'test/' + str(classifier_index) + '.csv'\n",
    "#     training_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "#     test_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "#     # Create dataframe for data and separate target.\n",
    "#     df_training = pd.DataFrame(training_set)\n",
    "#     y_training = df_training.iloc[:, -1]\n",
    "#     # Validation/testing data is loaded.\n",
    "#     df_test = pd.DataFrame(test_set)\n",
    "#     y_test = df_test.iloc[:, -1]\n",
    "#     # Classifier is trained using the data.\n",
    "#     classifiers[classifier_index].fit(df_training.iloc[:, :-1], y_training)\n",
    "#     # Classifier directory is generated if it doesn't exist.\n",
    "#     generar_jobs.generate_dir(model_base_path)\n",
    "#     # Classifier is persisted.\n",
    "#     joblib.dump(classifiers[classifier_index], model_base_path + model_file_prefix + str(classifier_index) \\\n",
    "#                 + model_file_extension)\n",
    "#     # Classifier accuracy is determined using test data.\n",
    "#     results = []\n",
    "#     for i in range(0, len(df_test)):\n",
    "#         # Every test example is classified, and its classification is appended\n",
    "#         # to a results array.\n",
    "#         results.append(classifiers[classifier_index].predict(\n",
    "#             df_test.iloc[i][:-1].values.reshape(1, -1)))\n",
    "#     # Actual results are compared to expected values.\n",
    "#     accuracy = accuracy_score(y_test, results)\n",
    "#     os.write(1,'Classifier ' + str(classifier_index) + ':\\n') # Print directly to console\n",
    "#     os.write(1, 'Accuracy: ' + str(accuracy) + ', ') # Print directly to console\n",
    "#     # Calculated accuracy is added to accuracies list.\n",
    "#     accuracy_scores.append(accuracy)\n",
    "# #     os.write(1, 'Training of classifier ' + str(classifier_index) + ' finished.\\n') \n",
    "#     return\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "# import multiprocessing\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     ##### VERSION 1 #####\n",
    "# #     jobs = []\n",
    "# #     for i in range(0, task_amount):\n",
    "# #         print('Starting training of classifier ' + str(i))\n",
    "# #         p = multiprocessing.Process(target=train_and_persist_classifier(i))\n",
    "# #         jobs.append(p)\n",
    "# #         p.start()\n",
    "#     ##### END VERSION 1 #####\n",
    "#     ##### VERSION 2 #####\n",
    "#     start = time.time()\n",
    "#     num_cores = multiprocessing.cpu_count() * 4\n",
    "#     # For every task, train a classifier.\n",
    "#     Parallel(n_jobs=num_cores)(delayed(train_and_persist_classifier)(i) for i in range(0,task_amount))\n",
    "#     end = time.time()\n",
    "#     print('The execution took ' + str(end - start) + ' seconds')    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section determines the average accuracy for the created classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average accuracy (for all classifiers) is calculated (nothing to do with threading).\n",
    "promedio = 0.\n",
    "score_amount = len(accuracy_scores)\n",
    "for i in range(0, score_amount):\n",
    "    promedio += accuracy_scores[i]\n",
    "promedio /= score_amount\n",
    "print ('The average accuracy is {}'.format(promedio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logToConsole(msg):\n",
    "    '''\n",
    "    Logs messages to console from within a Jupyter Notebook.\n",
    "    '''\n",
    "    os.write(1, msg + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No threading version.\n",
    "start = time.time()\n",
    "# Each index corresponds to an instance.\n",
    "makespan_instance_machines_heuristic = []\n",
    "makespan_instance_machines_prediction = []\n",
    "SCALE_DATA = True\n",
    "USE_PARAMETER_SELECTION = False\n",
    "# Within each index, there'll be an array of machine_amount elements, in which each element\n",
    "# is the time during which each machine is running\n",
    "# Something along the lines of [[10,20,9,40], [99,88,22,11], ..., [10,9,21,35]]\n",
    "for i in range(0, 1): # For each task/classifier\n",
    "    print(\"Training classifier \" + str(i) + \"...\")\n",
    "    # Data is loaded.\n",
    "    TRAINING_FILE = baseDir + 'training/' + str(i) + '.csv' # Training file for current classifier\n",
    "    TEST_FILE = baseDir + 'test/' + str(i) + '.csv' # Test file for current classifier\n",
    "    training_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "    test_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "    \n",
    "    # Create dataframe for data and separate target.\n",
    "    df_training = pd.DataFrame(training_set)\n",
    "    print(df_training)\n",
    "    df_training_input = df_training.iloc[:, :-1] \n",
    "    print(df_training_input.iloc[:, i * task_amount : i * task_amount + task_amount])\n",
    "    df_training_output = df_training.iloc[:, -1]\n",
    "    \n",
    "    # Validation/testing data is loaded.\n",
    "    df_test = pd.DataFrame(test_set)\n",
    "    df_test_input = df_test.iloc[:, :-1]\n",
    "    df_test_output = df_test.iloc[:, -1]\n",
    "    \n",
    "#     if SCALE_DATA:\n",
    "#         # Scale data because http://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use\n",
    "#         scaler = StandardScaler()  \n",
    "#         # Fit only on training data.\n",
    "#         scaler.fit(df_training_input)\n",
    "#         # Reconvert input training data to dataframe after scaling (which converts it to an array of arrays).\n",
    "#         df_training_input = pd.DataFrame(scaler.transform(df_training_input))\n",
    "#         # Re-init scaler just in case.\n",
    "#         scaler = StandardScaler()  \n",
    "#         scaler.fit(df_test_input)\n",
    "#         # Scale test data.\n",
    "#         df_test_input = pd.DataFrame(scaler.transform(df_test_input))        \n",
    "#     if current_classifier_str == CLASSIFIER_STRING_SVM:\n",
    "#         if USE_PARAMETER_SELECTION:\n",
    "#             # Grid of parameters, including all posible parameters for each configuration of\n",
    "#             # an SVM classifier.\n",
    "#             param_grid = [\n",
    "#               {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    "#              ]\n",
    "#             # Run grid search with all the possible classifier configurations.\n",
    "#             classifiers[i] = GridSearchCV(classifiers[i], param_grid=param_grid)\n",
    "#             # This generates multiple estimators.\n",
    "#             # Now the prediction will use the best estimator of all.\n",
    "#             # Should use grid_search as new classifier, persist it, and use it for prediction\n",
    "#             # as a normal classifier (according to documentation it uses the best estimator)\n",
    "#             # However, it fits every possible estimator with the data, so that's something of note.            \n",
    "#     # Classifier is trained using the data.\n",
    "#     classifiers[i].fit(df_training_input, df_training_output)\n",
    "#     # Classifier directory is generated if it doesn't exist.\n",
    "#     generar_jobs.generate_dir(model_base_path)\n",
    "#     # Classifier is persisted.\n",
    "#     joblib.dump(classifiers[i], model_base_path + model_file_prefix + str(i) \\\n",
    "#                 + model_file_extension)\n",
    "#     # Classifier accuracy is determined using test data.\n",
    "#     results = []\n",
    "#     # Go through every test instance manually to calculate makespan for each\n",
    "#     # problem-classifier/task pair\n",
    "#     current_task_index = i * machine_amount # Column index within etc matrix\n",
    "#     print(\"    Doing makespan stuff...\")\n",
    "#     test_instance_amount = len(df_test)\n",
    "#     for j in range(0, test_instance_amount): # For every validation instance\n",
    "#         # df_test.iloc[j] is an ETC matrix + the corresponding classification for one task\n",
    "#         etc_matrix_scaled = df_test_input.iloc[j] # Scaled data for classification (since classifiers were\n",
    "#         # trained using scaled data)\n",
    "#         # Non-scaled data is used to calculate real makespan, using the original units of the problem.\n",
    "#         etc_matrix = df_test.iloc[j][:-1] # Get j problem instance, ignoring last column (the output/classification).\n",
    "#         classification_heuristic = float(df_test_output[j])\n",
    "#         # Every test example is classified, and its classification is appended\n",
    "#         # to a results array.\n",
    "#         # Make prediction for current problem instance or etc matrix (using scaled data).\n",
    "#         prediction_pandas = float(classifiers[i].predict(etc_matrix_scaled.values.reshape(1, -1)))\n",
    "#         results.append(prediction_pandas)\n",
    "#         prediction = float(prediction_pandas) # To work in floats.\n",
    "\n",
    "#         # Get subrow from original input data, to get the task/machine times right.\n",
    "#         sub_row_for_current_task = etc_matrix[current_task_index:current_task_index + machine_amount]\n",
    "#         # Makespan value for prediction\n",
    "#         current_makespan_prediction = sub_row_for_current_task[current_task_index + prediction]\n",
    "#         # Makespan value for heuristic\n",
    "#         current_makespan_heuristic = sub_row_for_current_task[current_task_index + classification_heuristic]\n",
    "#         if len(makespan_instance_machines_prediction) <= j: # If there's no entry for this problem instance.\n",
    "#             # Init entry for problem instance, with each machine's makespan starting at 0.0.\n",
    "#             makespan_instance_machines_prediction.append([0.0] * machine_amount)\n",
    "#             makespan_instance_machines_heuristic.append([0.0] * machine_amount)\n",
    "#         makespan_instance_machines_prediction[j][int(prediction)] += current_makespan_prediction\n",
    "#         makespan_instance_machines_heuristic[j][int(classification_heuristic)] += current_makespan_heuristic\n",
    "#     print(\"    Done with makespan stuff...\")\n",
    "#     # Actual classification results are compared to expected values.\n",
    "#     accuracy = accuracy_score(df_test_output, results)\n",
    "#     print(\"    Classifier accuracy: \" + str(accuracy))\n",
    "#     # Calculated accuracy is added to accuracies list.\n",
    "#     accuracy_scores.append(accuracy)\n",
    "# end = time.time()\n",
    "# print('The execution took ' + str(end - start) + ' seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
