{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "import parser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import generar_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parámetros hardcodeados del problema a estudiar\n",
    "task_amount = 128\n",
    "machine_amount = 4\n",
    "task_heterogeneity = 0\n",
    "machine_heterogeneity = 0\n",
    "consistency_type = 0\n",
    "accuracy_scores = []\n",
    "classifiers = []\n",
    "\n",
    "dimension = task_amount * machine_amount\n",
    "\n",
    "# Referencia: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "ns = 600  # Cantidad de instancias de entrenamiento\n",
    "ni = dimension\n",
    "no = 1  # Cantidad de salidas\n",
    "alpha = 2\n",
    "hidden_layer_amount = int(math.ceil(ns / (alpha * (ni + no))))\n",
    "# Cada capa oculta tiene una cantidad de neuronas intermedia entre la cantidad\n",
    "# de salidas y entradas\n",
    "# Se pasa a una tupla para mandarlo al constructor del MLPClassifier\n",
    "hidden_layer_neuron_amount = tuple([int(math.ceil((task_amount - no) / 2))]\n",
    "                                   * hidden_layer_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision de clasificador: 0.513333333333\n",
      "Precision de clasificador: 0.465\n",
      "Precision de clasificador: 0.533333333333\n",
      "Precision de clasificador: 0.478333333333\n",
      "Precision de clasificador: 0.421666666667\n",
      "Precision de clasificador: 0.518333333333\n",
      "Precision de clasificador: 0.508333333333\n",
      "Precision de clasificador: 0.536666666667\n",
      "Precision de clasificador: 0.47\n",
      "Precision de clasificador: 0.501666666667\n",
      "Precision de clasificador: 0.501666666667\n",
      "Precision de clasificador: 0.548333333333\n",
      "Precision de clasificador: 0.515\n",
      "Precision de clasificador: 0.493333333333\n",
      "Precision de clasificador: 0.498333333333\n",
      "Precision de clasificador: 0.496666666667\n",
      "Precision de clasificador: 0.498333333333\n",
      "Precision de clasificador: 0.516666666667\n",
      "Precision de clasificador: 0.491666666667\n",
      "Precision de clasificador: 0.486666666667\n",
      "Precision de clasificador: 0.49\n",
      "Precision de clasificador: 0.461666666667\n",
      "Precision de clasificador: 0.48\n",
      "Precision de clasificador: 0.475\n",
      "Precision de clasificador: 0.443333333333\n",
      "Precision de clasificador: 0.495\n",
      "Precision de clasificador: 0.518333333333\n",
      "Precision de clasificador: 0.431666666667\n",
      "Precision de clasificador: 0.47\n",
      "Precision de clasificador: 0.498333333333\n",
      "Precision de clasificador: 0.475\n",
      "Precision de clasificador: 0.465\n",
      "Precision de clasificador: 0.535\n",
      "Precision de clasificador: 0.506666666667\n",
      "Precision de clasificador: 0.523333333333\n",
      "Precision de clasificador: 0.53\n",
      "Precision de clasificador: 0.508333333333\n",
      "Precision de clasificador: 0.498333333333\n",
      "Precision de clasificador: 0.526666666667\n",
      "Precision de clasificador: 0.491666666667\n",
      "Precision de clasificador: 0.513333333333\n",
      "Precision de clasificador: 0.506666666667\n",
      "Precision de clasificador: 0.501666666667\n",
      "Precision de clasificador: 0.476666666667\n",
      "Precision de clasificador: 0.465\n",
      "Precision de clasificador: 0.483333333333\n",
      "Precision de clasificador: 0.508333333333\n",
      "Precision de clasificador: 0.48\n",
      "Precision de clasificador: 0.503333333333\n",
      "Precision de clasificador: 0.338333333333\n",
      "Precision de clasificador: 0.48\n",
      "Precision de clasificador: 0.51\n",
      "Precision de clasificador: 0.501666666667\n",
      "Precision de clasificador: 0.425\n",
      "Precision de clasificador: 0.52\n",
      "Precision de clasificador: 0.498333333333\n",
      "Precision de clasificador: 0.483333333333\n",
      "Precision de clasificador: 0.495\n",
      "Precision de clasificador: 0.471666666667\n",
      "Precision de clasificador: 0.478333333333\n",
      "Precision de clasificador: 0.5\n",
      "Precision de clasificador: 0.501666666667\n",
      "Precision de clasificador: 0.506666666667\n",
      "Precision de clasificador: 0.516666666667\n",
      "Precision de clasificador: 0.468333333333\n",
      "Precision de clasificador: 0.523333333333\n",
      "Precision de clasificador: 0.515\n",
      "Precision de clasificador: 0.505\n",
      "Precision de clasificador: 0.488333333333\n",
      "Precision de clasificador: 0.506666666667\n",
      "Precision de clasificador: 0.496666666667\n",
      "Precision de clasificador: 0.521666666667\n",
      "Precision de clasificador: 0.516666666667\n",
      "Precision de clasificador: 0.496666666667\n",
      "Precision de clasificador: 0.51\n",
      "Precision de clasificador: 0.498333333333\n",
      "Precision de clasificador: 0.52\n",
      "Precision de clasificador: 0.518333333333\n",
      "Precision de clasificador: 0.503333333333\n",
      "Precision de clasificador: 0.421666666667\n",
      "Precision de clasificador: 0.513333333333\n",
      "Precision de clasificador: 0.505\n",
      "Precision de clasificador: 0.503333333333\n",
      "Precision de clasificador: 0.466666666667\n",
      "Precision de clasificador: 0.52\n",
      "Precision de clasificador: 0.523333333333\n",
      "Precision de clasificador: 0.5\n",
      "Precision de clasificador: 0.531666666667\n",
      "Precision de clasificador: 0.495\n",
      "Precision de clasificador: 0.486666666667\n",
      "Precision de clasificador: 0.531666666667\n",
      "Precision de clasificador: 0.495\n",
      "Precision de clasificador: 0.51\n",
      "Precision de clasificador: 0.5\n",
      "Precision de clasificador: 0.501666666667\n",
      "Precision de clasificador: 0.52\n",
      "Precision de clasificador: 0.305\n",
      "Precision de clasificador: 0.495\n",
      "Precision de clasificador: 0.506666666667\n",
      "Precision de clasificador: 0.488333333333\n",
      "Precision de clasificador: 0.486666666667\n",
      "Precision de clasificador: 0.501666666667\n",
      "Precision de clasificador: 0.521666666667\n",
      "Precision de clasificador: 0.503333333333\n",
      "Precision de clasificador: 0.495\n",
      "Precision de clasificador: 0.513333333333\n",
      "Precision de clasificador: 0.511666666667\n",
      "Precision de clasificador: 0.498333333333\n",
      "Precision de clasificador: 0.488333333333\n",
      "Precision de clasificador: 0.485\n",
      "Precision de clasificador: 0.496666666667\n",
      "Precision de clasificador: 0.518333333333\n",
      "Precision de clasificador: 0.48\n",
      "Precision de clasificador: 0.511666666667\n",
      "Precision de clasificador: 0.41\n",
      "Precision de clasificador: 0.51\n",
      "Precision de clasificador: 0.488333333333\n",
      "Precision de clasificador: 0.51\n",
      "Precision de clasificador: 0.508333333333\n",
      "Precision de clasificador: 0.496666666667\n",
      "Precision de clasificador: 0.483333333333\n",
      "Precision de clasificador: 0.521666666667\n",
      "Precision de clasificador: 0.52\n",
      "Precision de clasificador: 0.52\n",
      "Precision de clasificador: 0.443333333333\n",
      "Precision de clasificador: 0.548333333333\n",
      "Precision de clasificador: 0.508333333333\n",
      "Precision de clasificador: 0.475\n"
     ]
    }
   ],
   "source": [
    "# Path base para todos los clasificadores\n",
    "model_base_path = './models/' + str(task_amount) + 'x' + str(machine_amount) \\\n",
    "    + '-' + str(task_heterogeneity) + str(machine_heterogeneity) \\\n",
    "    + str(consistency_type) + '/'\n",
    "baseDir = './ejemplos-entrenamiento-unificados/' + str(task_amount) + 'x' \\\n",
    "    + str(machine_amount) + '-' + str(task_heterogeneity) \\\n",
    "    + str(machine_heterogeneity) + str(consistency_type) + '/'\n",
    "model_file_prefix = 'classifier'\n",
    "model_file_extension = '.pkl'\n",
    "\n",
    "for i in range(0, task_amount):\n",
    "    # Se crea clasificador o se carga si ya existe\n",
    "    try:\n",
    "        classifier = joblib.load(model_base_path + model_file_prefix + str(i) \\\n",
    "                                 + model_file_extension)\n",
    "    except Exception:\n",
    "        print('El clasificador para la salida ' + str(i) + ' no existía.')\n",
    "        classifier = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                                   hidden_layer_sizes=hidden_layer_neuron_amount,\n",
    "                                   random_state=1)\n",
    "    finally:\n",
    "        # Se agrega a lista de clasificadores\n",
    "        classifiers.append(classifier)\n",
    "\n",
    "for i in range(0, task_amount):\n",
    "    # Se cargan los datos\n",
    "    TRAINING_FILE = baseDir + 'training/' + str(i) + '.csv'\n",
    "    TEST_FILE = baseDir + 'test/' + str(i) + '.csv'\n",
    "    training_set = pd.read_csv(TEST_FILE, header=None, delimiter=',')\n",
    "    test_set = pd.read_csv(TRAINING_FILE, header=None, delimiter=',')\n",
    "    # Se crea dataframe para datos y se separa el target\n",
    "    df_training = pd.DataFrame(training_set)\n",
    "    y_training = df_training.iloc[:, -1]\n",
    "    # Se cargan datos de validacion\n",
    "    df_test = pd.DataFrame(test_set)\n",
    "    y_test = df_test.iloc[:, -1]\n",
    "    # Se entrena clasificador con datos\n",
    "    classifiers[i].fit(df_training.iloc[:, :-1], y_training)\n",
    "    # Se genera el directorio del clasificador si no existe\n",
    "    generar_jobs.generateDir(model_base_path)\n",
    "    # Se persiste\n",
    "    joblib.dump(classifiers[i], model_base_path + model_file_prefix + str(i) \\\n",
    "                + model_file_extension)\n",
    "    # Determino accuracy para este clasificador\n",
    "    results = []\n",
    "    for j in range(0, len(df_test)):\n",
    "        # Clasifico cada instancia del archivo de test, y agrego la clasificacion\n",
    "        # a un array de resultados\n",
    "        results.append(classifiers[i].predict(\n",
    "            df_test.iloc[j][:-1].values.reshape(1, -1)))\n",
    "    # Comparo los resultados con los esperados\n",
    "    accuracy = accuracy_score(y_test, results)\n",
    "    print(\"Precision de clasificador: \" + str(accuracy))\n",
    "    # Agrego accuracy a lista de accuracies\n",
    "    accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El promedio de accuracy es de 0.4948828125\n"
     ]
    }
   ],
   "source": [
    "# Calculo promedio de accuracy para todos los clasificadores\n",
    "promedio = 0.\n",
    "score_amount = len(accuracy_scores)\n",
    "for i in range(0, score_amount):\n",
    "    promedio += accuracy_scores[i]\n",
    "promedio /= score_amount\n",
    "print ('El promedio de accuracy es de {}'.format(promedio))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
