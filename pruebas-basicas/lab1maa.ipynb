{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de aprendizaje automático 2017 laboratorio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En esta primera etapa se realizará un experimento para mostrar cómo se puede aplicar erroneamente la selección de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relizamos la importación de los módulos necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn import feature_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos una matriz con 10000 características aleatorias y una etiqueta a predecir también con valores aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "X = np.random.randint(0,10,size=[100,10000])\n",
    "y = np.random.randint(0,2,size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos feature selection con el método de chi cuadrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = feature_selection.SelectKBest(feature_selection.chi2, k=20)\n",
    "X_fs = fs.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos un clasificador. En este caso una regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos validación cruzada para ver los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9047619   0.95        0.75        0.85        0.68421053]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_fs, y, cv=5, scoring='accuracy')\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar por qué si los números son generados al azar se obtienen buenos resultados. ¿Cómo solucionaría este problema?\n",
    "Resolver el problema utilizando pipelines de sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método de chi cuadrado se obtienen las 20 features que \"clasifican mejor\" a las instancias.\n",
    "Por más que se hayan generado todos los datos (valores por cada feature para cada instancia, y las respectivas clasificaciones para cada instancia) de forma aleatoria, y al tener inicialmente una cantidad considerablemente grande de features (10000), probablemente hayan features que casualmente ayuden a clasificar las instancias mejor que otros.\n",
    "Entonces, si a partir de un conjunto X nos quedamos con las 20 mejores features según chi cuadrado, y después aplicamos validación cruzada con un clasificador de regresión logística (LogisticRgression()) usando este X para luego definir los conjuntos de entrenamiento y de prueba, es esperable que dé buenos resultados para cada iteración de la validación cruzada, ya que tanto para el conjunto de entrenamiento como para el de prueba se usan los 20 features que mejor clasifican a ambos.\n",
    "Para solucionar el problema, la elección de los 20 features con chi cuadrado debería realizarse únicamente con los conjuntos de entrenamiento Xi de cada iteración, para luego evaluar contra un subconjunto de entrenamiento que no participó en la elección de las 20 mejores features. De esta forma obtenemos resultados más realistas de la precisión del clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57142857  0.45        0.45        0.45        0.47368421]\n"
     ]
    }
   ],
   "source": [
    "estimator = Pipeline([(\"fs\", fs),\n",
    "                      (\"clf\",clf)])\n",
    "scores = cross_val_score(estimator, X, y, cv=5, scoring='accuracy')\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para la siguiente parte trabajaremos con un conjunto de datos de textos. Para ello los descargamos.\n",
    "Una descripción del set de datos: http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train = fetch_20newsgroups(subset='train', categories=['talk.politics.guns', 'soc.religion.christian', 'comp.graphics', 'sci.med'], shuffle=True, random_state=42)\n",
    "test = fetch_20newsgroups(subset='test', categories=['talk.politics.guns', 'soc.religion.christian', 'comp.graphics', 'sci.med'], shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar un ejemplo de entrenamiento de cada una de las categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics :\n",
      "0    Subject: newss\\nFrom: pollarda@physc1.byu.edu\\...\n",
      "1                                                    0\n",
      "Name: 7, dtype: object\n",
      "sci.med :\n",
      "0    From: annick@cortex.physiol.su.oz.au (Annick A...\n",
      "1                                                    1\n",
      "Name: 5, dtype: object\n",
      "soc.religion.christian :\n",
      "0    From: Petch@gvg47.gvg.tek.com (Chuck Petch)\\nS...\n",
      "1                                                    2\n",
      "Name: 2, dtype: object\n",
      "talk.politics.guns :\n",
      "0    From: tms@cs.umd.edu (Tom Swiss (not Swift, no...\n",
      "1                                                    3\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "#generamos un dataframe para manejarlo con pandas\n",
    "#empaquetando cada dato con su respectivo target\n",
    "#cada target es un número del 0..3 que corresponde con el \n",
    "#indice de la categoría en el array train.target_names\n",
    "a = pd.DataFrame(zip(train.data,train.target))\n",
    "for category in train.target_names:\n",
    "    print category, \":\"\n",
    "    category_id = train.target_names.index(category)\n",
    "    print a.loc[a[1] == category_id].iloc[0,]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar el módulo CountVectorizer para extraer caracterísitcas a partir de texto y explicar cómo funciona. Explicar qué es el modelo de bolsa de palabras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolsa de palabras: Es un modelo de representación de documentos de texto. Estos se representan como sets de las palabras que lo conforman, sin tener en cuenta gramática u orden de palabras, manteniendo la multiplicidad de las mismas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer:A partir de un texto crea una estructura matricial, en la cual almacena el valor de la palabra y la cantidad de ocurrencias de la misma, al analizar una nueva palabra si la misma ya existia en la estructura aumenta la cantidad de ocurrencias, de lo contrario crea un nuevo registro. Esto se realiza por cada elemento del iterable de entrada. A continuación se muestra un ejemplo de la ejecución del CountVectorized y la generación del estimador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "content = [\"hola mundo hola\",\"hola hola hola otra\"]\n",
    "X = vectorizer.fit_transform(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imprimen las palabras que fueron tomadas como caracteristicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'hola', u'mundo', u'otra']\n"
     ]
    }
   ],
   "source": [
    "print vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada caracteristica, se muestra la cantidad de repeticiones de cada palabra. Las filas corresponden a cada entrada de la lista \"content\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "data = cv.fit_transform(list(a[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un clasificador bayesiano sencillo Multinomial. Explicar cada uno de los parámetros de este clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentran 3 parametros para la creación del clasificador Bayesiando Sencillo Multinomial:\n",
    "- alpha\n",
    "- fit_prior\n",
    "- class_prior\n",
    "\n",
    "\n",
    "Alpha:\n",
    "Es el parámetro de suavizado.\n",
    "Dada una instancia de entrenamiento, puede suceder que al momento de estimar la probabilidad condicionada a un target value 'y' para de una de las características 'c' del la instancia (en este caso son palabras dentro de un texto), si 'c' no figuró en ninguna instancia de entrenamiento con resultado 'y', la probabilidad calculada como la cantidad de ocurrencias de c con resultado 'y' en las instancias de entrenamiento sobre la cantidad total de instancias con resultado 'y', daría cero. El resultado nulo no es deseable ya que no es necesariamente representativo de la reaildad, posiblemente debido a que el conjunto de entrenamiento no fue lo suficientemente grande como para aproximar la probabilidad en cuestión. \n",
    "\n",
    "Por esto se re-define el cálculo de la probabilidad ya mencionada como:\n",
    "P(c/y) = (cant(c/y) + aplha)/ (cant(y) + alpha*n)\n",
    "\n",
    "Donde: \n",
    "- cant(c/y) es la cantidad de ocurrencias de la característica c en instancias de entrenamiendo con resultado 'y'\n",
    "- cant(y) es la cantidad de instancias con resultado y\n",
    "- n es la cantidad de características distintas\n",
    "- alpha es un real entre 0 y 1\n",
    "\n",
    "De esta forma, logramos obtener probabilidades pequeñas pero no nulas para todas las características que presentan la situación mencionada anteriormente.\n",
    "\n",
    "fit_prior:\n",
    "Es un parámetro booleano que cuando está en True, calcula por cada clasificación 'y', la probabilidad de que una instancia del conjunto de entrenamiento tomada al azar tenga clasificación 'y'. Cuando está seteada en False, asume una distribución uniforme.\n",
    "\n",
    "class_prior:\n",
    "Es un parámetro de tipo lista, que contiene las probabilidades para cada clasificación 'y'. Si el parámetro es epecificado, no se calculan las probabilidades de las clasificaciones en base al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método fit(X,y,sample_weight) que corresponde al clasificador MultinomialNB, entrenará el clasificador en base al conjunto de entrenamiento X y sus respectivos atributo objetivo 'y'. Así también, sample_weigth aplica pesos podnerando a cada uno de los ejemplos individuales, si no se especifica se asume que no hay pesos especiales para los ejemplos. A continuación entrenamos el clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data.toarray(), train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetir el proceso pero utilizando el módulo TfidfTransformer en lugar de CountVectorizer. Explicar la medida Tfidf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El factor TF es la suma de todas las ocurrencias ó el número de veces que aparece un término en un documento.\n",
    "El factor IDF de un término es inversamente proporcional al número de documentos en los que aparece dicho término. Es el coeficiente que determina la capacidad discriminatoria del término de un documento con respecto a la colección. Es decir, una medida de si el término es común o no, en la colección de documentos.\n",
    "\n",
    "La medida TF-TDF corresponde al peso de un término en un documento y se calcula como el producto de su frecuencia de aparición en dicho documento (TF) y su frecuencia inversa de documento (IDF).\n",
    "Un peso alto en TF-IDF se alcanza con una elevada frecuencia del término (en el documento dado) y una pequeña frecuencia de ocurrencia del término en la colección completa de documentos. Cuando un término aparece en muchos documentos, ofrece un valor de TF-IDF cercano a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza el siguiente vector de documentos para dar un ejemplo del funcionamiento de TfidfTransformer:\n",
    "\n",
    "content = [\"hola mundo hola\",\"hola hola hola otra\"]\n",
    "\n",
    "Ese vector fue utilizado en partes anteriores, siendo transformado por medio del CountVectorizer como se muestra a continuación:\n",
    "\n",
    "X = vectorizer.fit_transform(content)\n",
    "\n",
    "Así, el siguiente código muestra el uso del TfidfTransformer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'hola', u'mundo', u'otra']\n",
      "[[ 0.81818021  0.57496187  0.        ]\n",
      " [ 0.90554997  0.          0.42423963]]\n"
     ]
    }
   ],
   "source": [
    "dataTf = tfidf.fit_transform(X)\n",
    "print vectorizer.get_feature_names()\n",
    "print dataTf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluya los pasos de extracción de características y el clasificador dentro de un pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', vectorizer),\n",
    "                     ('tfidf', tfidf),\n",
    "                     ('clf', clf)])\n",
    "\n",
    "parameters = {\n",
    "    'vect__binary': (True, False), # If True, all non zero counts are set to 1.\n",
    "    'tfidf__use_idf': (True,False),\n",
    "    'tfidf__smooth_idf': (True,False),\n",
    "    'clf__alpha': (0.001, 0.5, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluir las métricas de precision, recall y fscore para cada cada una de las clases y la matriz de confusión probando contra el conjunto de testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.92313120047237662, 0.91224276033282514, 0.91250514740702227, None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "text_clf.fit(train.data,train.target)\n",
    "\n",
    "y_true = test.target\n",
    "y_pred = text_clf.predict(test.data)\n",
    "\n",
    "precision_recall_fscore_support(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluya una GridSearch para ver cuales son los mejores hiper-parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.986\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.001\n",
      "\ttfidf__smooth_idf: True\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__binary: True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(text_clf, parameters)\n",
    "grid_search.fit(train.data, train.target)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exlique cada uno de los parámetros de cada uno de los pasos del pipeline y pruebe con varios tipos de clasificadores de los vistos en el curso. ¿Con qué configuración de parámetros obtuvo mejores resultados? Aplique selección de atributos y valore los resultados obtenidos. Realice una prueba final contra el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exlique cada uno de los parámetros de cada uno de los pasos del pipeline:\n",
    "\n",
    "- clf alpha: es el parámetro utilizado durante el calculo de probabilidades. El mismo fue explicado anteriormente.\n",
    "\n",
    "- tfidf use_idf: Cuando es True, utiliza 'inverse-document-frequency reweighting' y no únicamente term-frequency. Lo que implica que se obtiene más información midiendo la frecuencia de cada término en el total de documentos.\n",
    "\n",
    "- tfidf smooth_idf: Simula agregar un documento que contiene cada término una vez. Esto se hace para prevenir divisiones entre cero.\n",
    "\n",
    "- vect binary: No cuenta las repeticiones. Para aquellos valores del CountVectorized que den mayor que cero, los setea a 1, haciendo que la matiz de conteo se transforme en una matriz binaria, contando la aparición o no de la palabra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repita el ejercicio utilizando HashingVectorizer para extraer características. Explique las ventajas de este método de extracción de caraterísticas frente a CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementacion de hashVectorizer utiliza la funcion de hash para para encontrar el nombre de la cadena de tokens para la \n",
    "asignacion de indice de enteros.\n",
    "\n",
    "Ventajas frente a CountVectorizer:\n",
    "- Es muy baja la memoria escalable a los datasets grandes ya que no hay necesidad de almacenar un diccionario de vocabulario en la memoria\n",
    "- Es muy rapido para serializar y deserializar ya que no tiene ningun estado, ademas de los parametros del constructor.\n",
    "- Se puede utilizar en pipeline paralelo ya que no hay ningun estado calculado durante el ajuste.\n",
    "\n",
    "Desventajas frente a CountVectorizer:\n",
    "- No hay manera de calcular la transformacion inversa (de los indices de caracteistica a los nombres de la caracteristica \n",
    "de la secuencia) que puede ser un problema al intentar obtener que caracteristicas son las mas importantes a un modelo.\n",
    "- Puede haber colisiones: los tokens distintos se pueden asignar al mismo indice de caracteristicas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
